{
  "hash": "66b16a0ef939cad2c992869d15bfd48f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: SciPy\n---\n\n\n\n\n\n\n# Why SciPy?\n\n## What is SciPy?\n\n> [SciPy (pronounced “Sigh Pie”) is an open-source software for mathematics, science, and engineering.](https://docs.scipy.org/doc/scipy/index.html)\n\n* **Sci**entific **Py**thon\n* Basically a NumPy extension.\n\n## Why SciPy \n\n* Most popular scientific computing platform in the world.\n* Basis of scikit-learn, the most popular machine learning platform in the world.\n* Extremely rigorous - most functions and documentation come with academic citations.\n\n## Why not SciPy\n\n- SciPy for statistics has basically one challenger (statsmodels, which is great).\n- Sometimes SciPy is too \"heavyweight\" and NumPy would be sufficient.\n- As a rule, I tend to use NumPy for easy things and scikit-learn for hard things, and don't use SciPy for much.\n\n## Relevance\n\n- This is a scientific computing course!\n- We'll do a bit of signal processing and interpolation.\n\n## Credits\n\n- SciPy is a big, complex library with many components.\n- I used each of:\n  \t- The [User Guide](https://docs.scipy.org/doc/scipy/tutorial/index.html)\n\t- The [API reference](https://docs.scipy.org/doc/scipy/reference/index.html)\n\t  \t- API is \"application program interface\" - a description of the functions in SciPy by their arguments and return values.\n\t- The [Cookbook](https://scipy-cookbook.readthedocs.io/) which may be unofficial.\n\n# Install\n\n## pip again\n\n- Just like NumPy, Matplotlib is a Python package which we install via `pip`\n```{.bash code-line-numbers=\"false\"}\npython3 -m pip install scipy\n```\n- That might take a moment, when it does we can check it worked!\n\n## Verify\n\n- We can quickly verify installation and introduce some conventions.\n- Open up Python and import the libraries:\n\n::: {#8b5b66b2 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\n\nprint(scipy.__version__)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.14.1\n```\n:::\n:::\n\n\n# Other Installs\n\n## Motivation\n\n- I thought it would be fun to do some signal processing on a recognizable data set:\n- [PSY - GANGNAM STYLE(강남스타일) M/V](https://www.youtube.com/watch?v=9bZkp7q19f0)\n\n## YouTube \n\n::: {.callout-tip}\n## STOP\n\nInstructor's note:  Do not click this link while streaming.\n:::\n\n\n\n\n\n\n{{< video https://www.youtube.com/watch?v=9bZkp7q19f0 >}}\n\n\n\n\n\n\n\n\n\n\n## Problem Statement\n\n- SciPy has the ability to read some filetypes but not others.\n  \t- Can read: \".wav\" Waveform Audio File Format.\n\t- Can't read: YouTube urls\n- We use Python package `yt-dlp` to download from YouTube.\n- We use non-Python package `ffmpeg` to translate .mp4 files to .wav\n- We use VideoLAN VLC Media Player to play the .wav files.\n\n## Note\n\n- You do not need to download any of these.\n- Here is the .wav:\n\t- <audio controls src=\"src/psy.wav\" type=\"audio/wav\"></audio> \n- Here is a link: \n  \t- [psy.wav](psy.wav)\n\n## yt-dlp\n\n- While I don't think you need it for anything, I installed `yt-dlp` as follows, from the shell:\n```{.bash code-line-numbers=\"false\"}\npython -m pip install yt-dlp\n```\n\n## ffmpeg\n\n- I believe this is the best place to download `ffmpeg` for Windows and MacOS.\n- [https://www.ffmpeg.org/download.html](https://www.ffmpeg.org/download.html)\n- I used it on Ubuntu Linux and did not attempt and Windows or MacOS install.\n\n## Download\n\n- Both `yt-dlp` and `ffmpeg` are command line utilites (like Python, Neovim, or `ls`).\n- I didn't actually ever use `ffmpeg` directly, it is just used by `yt-dlp`.\n- Given the url, I used the following shell command:\n```{.bash code-line-numbers=\"false\"}\nyt-dlp -x --audio-format wav https://www.youtube.com/watch?v=9bZkp7q19f0 -o psy.wav\n```\n- This tells `yt-dlp` to go to the url, download to video, convert it to a .wav, and save it as \"psy.wav\"\n\n## VLC\n\n- I *highly* recommend having VLC installed.\n- [https://www.videolan.org/vlc/#download](https://www.videolan.org/vlc/#download)\n\n## curl\n\n- As an alternative, you can `curl` the file.\n  \t- Just the one I extracted.\n- The `curl` shell command downloads files from urls.\n  \t- Can also be used to get \".csv\" files for **pandas**!\n\n```{.bash code-line-number=\"false\"}\ncurl https://github.com/cd-public/scicom/raw/refs/heads/main/qmd/src/psy.wav -o psy.wav\n```\n\n- This directs the command line to download the file from the url and save it locally as \"psy.wav\"\n\n# `scipy.io`\n\n## wavfile\n\n- To load a wavfile into SciPy, it is a simple matter.\n- But first, we note one difference:\n  \t- With NumPy, we imported as `np`\n\t- With **pandas**, we import as `pd`\n- With Matplotlib, we imported Matplotlib \"dot\" something - pyplot\n  \t- The \"Python interface\"\n\n## SciPy Modules\n\n- SciPy is composed of many *modules*\n- `matplotlib.pyplot` is a previous example of a module.\n- For example:\n  \t- `scipy.io` includes ways to read files.\n\t- `scipy.fft` does Fast Fourier Transforms.\n\t- `scipy.stats` does statistics.\n\n## Load \"psy.wav\"\n\n- We will load a sound file as an np.array.\n\n::: {#66a6de05 .cell execution_count=2}\n``` {.python .cell-code}\nrate, data = scipy.io.wavfile.read(\"psy.wav\")\n```\n:::\n\n\n- This may look odd!\n\n## Multiple return\n\n- This uses a slightly advanced Python topic of \"multiple return\".\n\n::: {#3d72e2ed .cell execution_count=3}\n``` {.python .cell-code}\ndef roots(x):\n\troot = np.sqrt(x)\n\treturn -root, root\n```\n:::\n\n\n- Python can return multiple comma-separated values from a function.\n\n::: {#4f99c5a1 .cell execution_count=4}\n``` {.python .cell-code}\nneg, pos = roots(25)\n[neg, pos]\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n[np.float64(-5.0), np.float64(5.0)]\n```\n:::\n:::\n\n\n- We can \"unpack\" the multiple values by providing comma separated variable names.\n\n## Aside: Tuples\n\n- These multiple returns are just tuples.\n\t- The things that are like lists, but not exactly.\n\n::: {#78aa9996 .cell execution_count=5}\n``` {.python .cell-code}\nboth = roots(64)\ntype(both)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\ntuple\n```\n:::\n:::\n\n\n- We can also use indexing to see individual elements of a tuple.\n\n::: {#02facde5 .cell execution_count=6}\n``` {.python .cell-code}\nboth[0]\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nnp.float64(-8.0)\n```\n:::\n:::\n\n\n## vs. Lists\n\n- The only difference compared to lists is updates.\n- In a list, we can change an element with its index:\n\n::: {#be076d7d .cell execution_count=7}\n``` {.python .cell-code}\ncolor_lst = [\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\"]\ncolor_lst[-1] = \"purple\"\ncolor_lst\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n['red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'purple']\n```\n:::\n:::\n\n\n## Aside: Errors\n\n- Attempting updates to a *tuple* will error.\n- Thus far we have avoided showing example code that won't work.\n- We can use `try` and `except` (like `if` and `else`) on erroneous code.\n\n::: {#cdd30d8c .cell execution_count=8}\n``` {.python .cell-code}\ncolor_tup = tuple(color_lst)\ntry:\n\tcolor_tup[-1] = \"violet\"\nexcept:\n\tprint(\"Tuples can't do that.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTuples can't do that.\n```\n:::\n:::\n\n\n## Reading files\n\n- Try/except is *very* handy when reading files.\n- A lot of files I try to read are garbled and can't be read.\n- Using `try` and `except` prevents Python errors.\n  \t- More useful in big scripts than single-line things.\n\n## Example\n\n- While making these slides, I tried the `curl` command to get \"psy.wav\" while (unbeknownst to me) my internet was spotty.\n- I got a file named \"psy.wav\" that was of size `0`\n- Unsurprisingly, opening it with SciPy led to an error.\n- This happens all the time!\n\n## Data\n\n- Back to our .wav file.\n- Let's look at that data!\n\n::: {#85f2bcde .cell execution_count=9}\n``` {.python .cell-code}\ndata[:10]\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\narray([[0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0]], dtype=int16)\n```\n:::\n:::\n\n\n## Rate\n\n::: {#ecac0258 .cell execution_count=10}\n``` {.python .cell-code}\nrate\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n48000\n```\n:::\n:::\n\n\n- You may have listened to the file (or not).\n- Audio doesn't come in for about 4 seconds.\n- The song ends and there's a kind of \"outro\".\n- We can see these on the plot.\n- But that explains the zeros.\n\n## Plot\n\n::: {#ed41b26e .cell execution_count=11}\n``` {.python .cell-code}\nplt.plot(data)\n```\n\n::: {.cell-output .cell-output-display}\n![](07_scipy_files/figure-html/cell-12-output-1.png){width=603 height=428}\n:::\n:::\n\n\n## Back to Data\n\n- Given the rate, we can look at values ever `rate` amount of time.\n- I bet it's seconds, so we'll see 3 or 4 zero-only then some non-zero.\n\n::: {#2cd44a8e .cell execution_count=12}\n``` {.python .cell-code}\ndata[:rate*10:rate]\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\narray([[     0,      0],\n       [     0,      0],\n       [     0,      0],\n       [     0,      0],\n       [    -2,      3],\n       [-13903, -13896],\n       [ 12440,  12442],\n       [  6053,   6051],\n       [  5888,   5888],\n       [    53,     52]], dtype=int16)\n```\n:::\n:::\n\n\n## Why pairs?\n\n- Those two values may look initially suspicious, then I remembered.\n- Many mammals, including some assistant professors of computer science, have two ears!\n- This is a stereo file - the pairs are for each of two speakers.\n\n## Test it\n\n- Don't believe me?\n- Let's split into a \"left\" and \"right\" file.\n- We needn't necessarily get the labels right, but these are simply NumPy operations.\n- Then listen!\n\n## Transpose\n\n- Remember `.transpose`?\n- It will take an array of pairs and make a pair of arrays.\n\n::: {#3af95c30 .cell execution_count=13}\n``` {.python .cell-code}\ntpose = data.transpose()\ntpose[0][:rate*10:rate]\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\narray([     0,      0,      0,      0,     -2, -13903,  12440,   6053,\n         5888,     53], dtype=int16)\n```\n:::\n:::\n\n\n## Split\n\n- I will arbitrarily call one \"left\" and one \"rite\" (not \"right\" because we don't know if we're right).\n\n::: {#1294a07a .cell execution_count=14}\n``` {.python .cell-code}\nleft = tpose[0]\nrite = tpose[1]\n```\n:::\n\n\n## Zeros\n\n- We'll also make a zero-only array of the same length.\n\n::: {#1f7462b1 .cell execution_count=15}\n``` {.python .cell-code}\n# We note the \"dtype\" was \"int16\" so we do the same.\n# We do have to be clear it's NumPy int16 though!\nzero = np.zeros(len(left),dtype=np.int16)\n```\n:::\n\n\n## Combine\n\n- We can make left-only and rite-only arrays via:\n  - Combine\n  - Transpose\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {#047a243d .cell execution_count=16}\n``` {.python .cell-code}\nleft_only = np.array([left,zero]).transpose()\nleft_only[:rate*10:rate]\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\narray([[     0,      0],\n       [     0,      0],\n       [     0,      0],\n       [     0,      0],\n       [    -2,      0],\n       [-13903,      0],\n       [ 12440,      0],\n       [  6053,      0],\n       [  5888,      0],\n       [    53,      0]], dtype=int16)\n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#8f73d9eb .cell execution_count=17}\n``` {.python .cell-code}\nrite_only = np.array([zero,rite]).transpose()\nrite_only[:rate*10:rate]\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\narray([[     0,      0],\n       [     0,      0],\n       [     0,      0],\n       [     0,      0],\n       [     0,      3],\n       [     0, -13896],\n       [     0,  12442],\n       [     0,   6051],\n       [     0,   5888],\n       [     0,     52]], dtype=int16)\n```\n:::\n:::\n\n\n:::\n\n::::\n\n\n## Save\n\n- Let's write/save both then give 'um a listen.\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {#98a7578e .cell execution_count=18}\n``` {.python .cell-code}\nscipy.io.wavfile.write(\"left.wav\", rate, left_only)\n```\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#77cd6f64 .cell execution_count=19}\n``` {.python .cell-code}\nscipy.io.wavfile.write(\"rite.wav\", rate, rite_only)\n```\n:::\n\n\n:::\n\n::::\n\n## Listen \n\n- Let's write/save both then give 'um a listen.\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n\n\n<audio controls src=\"src/left.wav\" type=\"audio/wav\"></audio> \n\n:::\n\n::: {.column width=\"50%\"}\n\n\n<audio controls src=\"src/rite.wav\" type=\"audio/wav\"></audio> \n\n:::\n\n::::\n\n# Noise\n\n## Noise Reduction\n\n- In a way, all sound is noise.\n- Let's try and isolate the vocals and music, regarding the other variously as noise at various points.\n- First identify where vocals come in.\n- To me, 0:04 to 0:09 seems instrumental.\n\n## View it\n\n- Look for patterns\n\n::: {#ef608069 .cell execution_count=20}\n``` {.python .cell-code}\nsnip = left[4*rate:10*rate]\nplt.plot(snip)\n```\n\n::: {.cell-output .cell-output-display}\n![](07_scipy_files/figure-html/cell-21-output-1.png){width=624 height=411}\n:::\n:::\n\n\n## Repeats?\n\n- Looks like volume cuts low on a repeated pattern.\n- Maybe we can isolate that pattern.\n- Let's:\n  \t- Pick a range\n\t- Find a minimal value\n\t- Find where that value occurs.\n\n::: {#f9bbe627 .cell execution_count=21}\n``` {.python .cell-code}\nlow_val = min(snip)\nlow_val\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\nnp.int16(-32071)\n```\n:::\n:::\n\n\n## Whoops!\n\n- Oh we need to use absolute value.\n- No worries!\n\n::: {#e43d13b5 .cell execution_count=22}\n``` {.python .cell-code}\nlow_val = min(np.absolute(snip))\nlow_val\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\nnp.int16(0)\n```\n:::\n:::\n\n\n# Where?\n\n- Use `np.where` to find where the low values occur.\n  \t- We used with [**pandas**](06_pandas.qmd#metallic)\n\n::: {#fc5c07e9 .cell execution_count=23}\n``` {.python .cell-code}\nlows = np.where(snip == 0)\nlows\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\n(array([    13,     14,     18,     20,     31,     39,     44,    126,\n           127,    136,    137,    138,    148,    155,    157,    174,\n           176,    193,    197,    202,    219,    221,    222,    223,\n           231,    232,    262,    268,    317,    383,    405,    430,\n         13580,  25648,  26839,  28676,  29655,  64732, 131187, 131204,\n        153051, 210217, 216983, 271632, 278282]),)\n```\n:::\n:::\n\n\n## Patterns\n\n- Maybe there's something repeating on a periodicity of like... 65k?\n\n::: {#9b49f6ab .cell execution_count=24}\n``` {.python .cell-code}\n# We note that the result was enclosed in () so we get the [0] of it.\nlows = lows[0]\n# Then proceed\nlows = lows[np.where(lows > 500)]\nlows\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\narray([ 13580,  25648,  26839,  28676,  29655,  64732, 131187, 131204,\n       153051, 210217, 216983, 271632, 278282])\n```\n:::\n:::\n\n\n## Visualize\n\n- Let's just plot the place the minimum occurs.\n\n::: {#665fd799 .cell execution_count=25}\n``` {.python .cell-code}\n_ = plt.hist(lows)\n```\n\n::: {.cell-output .cell-output-display}\n![](07_scipy_files/figure-html/cell-26-output-1.png){width=558 height=411}\n:::\n:::\n\n\n## More Bins\n\n- Hard to see, we increase the \"bin\" count.\n\n::: {#11110a18 .cell execution_count=26}\n``` {.python .cell-code}\n_ = plt.hist(lows, 100)\n```\n\n::: {.cell-output .cell-output-display}\n![](07_scipy_files/figure-html/cell-27-output-1.png){width=579 height=411}\n:::\n:::\n\n\n## A Pattern?\n\n::: {#74940418 .cell execution_count=27}\n``` {.python .cell-code}\n_ = plt.hist(np.where(left == 0))\n```\n\n::: {.cell-output .cell-output-display}\n![](07_scipy_files/figure-html/cell-28-output-1.png){width=600 height=428}\n:::\n:::\n\n\n- Only before vocals enter?\n\n## Isolate\n\n- Let's see if we can isolate a motif.\n- We'll take the first zero past.\n- I hear about two repeats on this portion, so we'll take a zero in the middle.\n\n::: {#22883784 .cell execution_count=28}\n``` {.python .cell-code}\nnp.where(snip == 0)\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```\n(array([    13,     14,     18,     20,     31,     39,     44,    126,\n           127,    136,    137,    138,    148,    155,    157,    174,\n           176,    193,    197,    202,    219,    221,    222,    223,\n           231,    232,    262,    268,    317,    383,    405,    430,\n         13580,  25648,  26839,  28676,  29655,  64732, 131187, 131204,\n        153051, 210217, 216983, 271632, 278282]),)\n```\n:::\n:::\n\n\n## Motif\n\n::: {#d35af779 .cell execution_count=29}\n``` {.python .cell-code}\nstereo = np.array([snip,snip]).transpose()\nmotif = stereo[13580:131204]\nscipy.io.wavfile.write(\"motif.wav\", rate, motif)\n# os.system(\"open motif.wav\") # After import, if you have VLC, on MacOS\n```\n:::\n\n\n<audio controls src=\"src/motif.wav\" type=\"audio/wav\"></audio> \n\n::: {#dbe585f3 .cell execution_count=30}\n``` {.python .cell-code}\nother = stereo[13580:271632]\nscipy.io.wavfile.write(\"other.wav\", rate, other)\n```\n:::\n\n\n<audio controls src=\"src/motif.wav\" type=\"audio/wav\"></audio> \n\n::: {#d7db9cb6 .cell execution_count=31}\n``` {.python .cell-code}\nscipy.io.wavfile.write(\"motifs.wav\", rate, np.concatenate([motif,motif,motif]))\nscipy.io.wavfile.write(\"others.wav\", rate, np.concatenate([other,other,other]))\n```\n:::\n\n\n<audio controls src=\"src/motifs.wav\" type=\"audio/wav\"></audio> \n\n<audio controls src=\"src/others.wav\" type=\"audio/wav\"></audio> \n\n- You can go become a dj, or...\n\n## FFT\n\n- The actual correct way to do this is with a SciPy FFT:\n  \t- [Fast Fourier Transform](https://docs.scipy.org/doc/scipy/tutorial/fft.html)\n- And with a NumPy stride:\n  \t- [Stride Tricks](https://numpy.org/devdocs/reference/generated/numpy.lib.stride_tricks.html)\n- Which is probably a bit much for now.\n\n# Stats\n\n## Regression\n\n- One of the most used computation techniques is regression.\n- It is used throughout the sciences, but most commonly in econometrics.\n- In my my undergraduate economics class, I had a homework assignment to \"prove\" that raising minimum wage increases unemployment.\n  \t- It doesn't, but that isn't relevant here.\n\n## The Data\n\n- I usually get economic data from the \"St. Louis Fed\" which has a data portal called \"FRED\".\n  - Minimum wage [FEDMINNFRWG](https://fred.stlouisfed.org/series/FEDMINNFRWG)\n  - Unemployment rage [UNRATE](https://fred.stlouisfed.org/series/UNRATE)\n  - Inflation [CPIAUCSL](https://fred.stlouisfed.org/series/CPIAUCSL)\n\n## curl\n\n- It is actually possible to `curl` these but you probably have to navigate the websites to find the urls regardless.\n- I retrieved these manually on MS Windows on 31 May 2025 at 7:33 PM PT.\n```{.bash code-line-numbers=\"false\"}\ncurl https://github.com/cd-public/scicom/raw/refs/heads/main/qmd/src/FEMINNFRWG.csv -o FEDMINNFRWG.csv\ncurl https://github.com/cd-public/scicom/raw/refs/heads/main/qmd/src/UNRATE.csv-o UNRATE.csv\ncurl https://github.com/cd-public/scicom/raw/refs/heads/main/qmd/src/CPIAUCSL.csv -o CPIAUCSL.csv\n```\n\n## Within Python\n\n- You can of course also get these with out leaving Python.\n- Given some url with Python \n  - `url = \"https://...\"`\n- You can of course also:\n  - **pandas** `pd.read_csv(url)`\n  - \"os\" `os.system(\"curl \" + url + \" -o name.csv\")`\n\n## How I did it\n\n::: {#11d276f7 .cell execution_count=32}\n``` {.python .cell-code}\nimport pandas as pd\n\nminwage = pd.read_csv(\"https://github.com/cd-public/scicom/raw/refs/heads/main/qmd/src/FEDMINNFRWG.csv\")\nunemploy = pd.read_csv(\"https://github.com/cd-public/scicom/raw/refs/heads/main/qmd/src/UNRATE.csv\")\ninflate = pd.read_csv(\"https://github.com/cd-public/scicom/raw/refs/heads/main/qmd/src/CPIAUCSL.csv\")\ninflate\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>observation_date</th>\n      <th>CPIAUCSL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1947-01-01</td>\n      <td>21.480</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1947-02-01</td>\n      <td>21.620</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1947-03-01</td>\n      <td>22.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1947-04-01</td>\n      <td>22.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1947-05-01</td>\n      <td>21.950</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>935</th>\n      <td>2024-12-01</td>\n      <td>317.603</td>\n    </tr>\n    <tr>\n      <th>936</th>\n      <td>2025-01-01</td>\n      <td>319.086</td>\n    </tr>\n    <tr>\n      <th>937</th>\n      <td>2025-02-01</td>\n      <td>319.775</td>\n    </tr>\n    <tr>\n      <th>938</th>\n      <td>2025-03-01</td>\n      <td>319.615</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>2025-04-01</td>\n      <td>320.321</td>\n    </tr>\n  </tbody>\n</table>\n<p>940 rows × 2 columns</p>\n</div>\n```\n:::\n:::\n\n\n## Check Columns\n\n::: {#a657f01b .cell execution_count=33}\n``` {.python .cell-code}\nminwage.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```\nIndex(['observation_date', 'FEDMINNFRWG'], dtype='object')\n```\n:::\n:::\n\n\n::: {#e09acf0b .cell execution_count=34}\n``` {.python .cell-code}\nunemploy.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\nIndex(['observation_date', 'UNRATE'], dtype='object')\n```\n:::\n:::\n\n\n::: {#dbc6c391 .cell execution_count=35}\n``` {.python .cell-code}\ninflate.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```\nIndex(['observation_date', 'CPIAUCSL'], dtype='object')\n```\n:::\n:::\n\n\n## Merge\n\n- This is suitable for a merge.\n- Alternatively, set date as index then join.\n\n::: {#1f49e05c .cell execution_count=36}\n``` {.python .cell-code}\ndf = minwage.merge(unemploy).merge(inflate)\ndf = df.drop(columns=[\"observation_date\"])\ndf[:3]\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FEDMINNFRWG</th>\n      <th>UNRATE</th>\n      <th>CPIAUCSL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.4</td>\n      <td>3.4</td>\n      <td>23.68</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.4</td>\n      <td>3.8</td>\n      <td>23.67</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.4</td>\n      <td>4.0</td>\n      <td>23.50</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Adjustments\n\n- Unemployment rate is rate.\n- Minimum wage is a nominal value (e.g. it's units are ill-defined).\n- Inflation is an index of wage units.\n- We can divide wage by inflation to get a \"real wage\".\n\n::: {#8cbf53e1 .cell execution_count=37}\n``` {.python .cell-code}\n# I made so many types here.\n# In a pinch use df[df.columns[0]]\ndf[\"REAL\"] = df[\"FEDMINNFRWG\"] / df[\"CPIAUCSL\"]\n```\n:::\n\n\n## Percent Change\n\n- We measure percent change in real wages.\n  \t- We use **pandas** `.pct_change()`\n\t  \t- It's recommend by SciPy\n\t- We drop the *row* `0` which has no percent change.\n\t\t- Drop rows by index, vs `column=<name>`\n\t- We drop an undefined (\"NaN\") values\n\n::: {#1ad87925 .cell execution_count=38}\n``` {.python .cell-code}\ndf[\"REALPCT\"] = df[\"REAL\"].pct_change()\ndf.drop(0)\ndf = df.dropna()\n```\n:::\n\n\n## Unemployment\n\n- Oh we should probably take a percentage change in unemployment as well.\n\n::: {#d8b7b1e5 .cell execution_count=39}\n``` {.python .cell-code}\ndf[\"UNRATE\"] = df[\"UNRATE\"].pct_change()\n```\n:::\n\n\n## Look at it\n\n::: {#1fd948de .cell execution_count=40}\n``` {.python .cell-code}\nplt.xlabel(\"REALPCT\")\nplt.ylabel(\"UNRATE\")\n_ = plt.scatter(df[\"REALPCT\"],df[\"UNRATE\"])\n```\n\n::: {.cell-output .cell-output-display}\n![](07_scipy_files/figure-html/cell-41-output-1.png){width=589 height=429}\n:::\n:::\n\n\n## Linear Regression\n\n- The standard measure of statistical significance.\n- We are assuming linearity, but it is already a comparison between rates.\n- For more, study statistics!\n\n::: {#7ad1b227 .cell execution_count=41}\n``` {.python .cell-code}\nfrom scipy import stats\n```\n:::\n\n\n## `linregress`\n\n::: {#f5519434 .cell execution_count=42}\n``` {.python .cell-code}\nres = stats.linregress(df[\"REALPCT\"],df[\"UNRATE\"])\nprint(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinregressResult(slope=np.float64(nan), intercept=np.float64(nan), rvalue=np.float64(nan), pvalue=np.float64(nan), stderr=np.float64(nan), intercept_stderr=np.float64(nan))\n```\n:::\n:::\n\n\n## Tada!\n\n- Raising minimum wage doesn't predictable impact unemployment.\n\n# Exercise\n\n## Technetium\n\n- We recall the periodic table data\n\n::: {#73674236 .cell execution_count=43}\n``` {.python .cell-code}\ndf = pd.read_csv(\"https://gist.githubusercontent.com/GoodmanSciences/c2dd862cd38f21b0ad36b8f96b4bf1ee/raw/1d92663004489a5b6926e944c1b3d9ec5c40900e/Periodic%2520Table%2520of%2520Elements.csv\")\ndf[::30]\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AtomicNumber</th>\n      <th>Element</th>\n      <th>Symbol</th>\n      <th>AtomicMass</th>\n      <th>NumberofNeutrons</th>\n      <th>NumberofProtons</th>\n      <th>NumberofElectrons</th>\n      <th>Period</th>\n      <th>Group</th>\n      <th>Phase</th>\n      <th>...</th>\n      <th>FirstIonization</th>\n      <th>Density</th>\n      <th>MeltingPoint</th>\n      <th>BoilingPoint</th>\n      <th>NumberOfIsotopes</th>\n      <th>Discoverer</th>\n      <th>Year</th>\n      <th>SpecificHeat</th>\n      <th>NumberofShells</th>\n      <th>NumberofValence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Hydrogen</td>\n      <td>H</td>\n      <td>1.007</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>gas</td>\n      <td>...</td>\n      <td>13.5984</td>\n      <td>0.00009</td>\n      <td>14.175</td>\n      <td>20.28</td>\n      <td>3.0</td>\n      <td>Cavendish</td>\n      <td>1766.0</td>\n      <td>14.304</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>31</td>\n      <td>Gallium</td>\n      <td>Ga</td>\n      <td>69.723</td>\n      <td>39</td>\n      <td>31</td>\n      <td>31</td>\n      <td>4</td>\n      <td>13.0</td>\n      <td>solid</td>\n      <td>...</td>\n      <td>5.9993</td>\n      <td>5.91000</td>\n      <td>302.910</td>\n      <td>2477.00</td>\n      <td>14.0</td>\n      <td>de Boisbaudran</td>\n      <td>1875.0</td>\n      <td>0.371</td>\n      <td>4</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>61</td>\n      <td>Promethium</td>\n      <td>Pm</td>\n      <td>145.000</td>\n      <td>84</td>\n      <td>61</td>\n      <td>61</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>artificial</td>\n      <td>...</td>\n      <td>5.5820</td>\n      <td>7.26000</td>\n      <td>1204.150</td>\n      <td>3273.00</td>\n      <td>14.0</td>\n      <td>Marinsky et al.</td>\n      <td>1945.0</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>91</td>\n      <td>Protactinium</td>\n      <td>Pa</td>\n      <td>231.036</td>\n      <td>140</td>\n      <td>91</td>\n      <td>91</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>solid</td>\n      <td>...</td>\n      <td>5.8900</td>\n      <td>15.40000</td>\n      <td>1873.150</td>\n      <td>4300.00</td>\n      <td>14.0</td>\n      <td>Hahn and Meitner</td>\n      <td>1917.0</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 28 columns</p>\n</div>\n```\n:::\n:::\n\n\n## Interpolation\n\n- When first setting out the table, a number of elements had not yet been \"observed\"\n  \t- That is, no one determined their chemical properties while away they were an element.\n- Some *certainly* were never observed, namely technetium (Tc, 43) which does not exist in nature.\n- However, the layout of the table allowed scientists to predict properties of technetium \n\n## Extract\n\n- We will:\n  \t- Set aside technetium in a variable to check our predictions against.\n\t- Remove the \"transuranic\" elements which were also not yet observed.\n\n::: {#255b3af5 .cell execution_count=44}\n``` {.python .cell-code}\ndf = df.iloc[:91]\nTc = df.iloc[42]\ndf = df.drop(42)\nTc\n```\n\n::: {.cell-output .cell-output-display execution_count=44}\n```\nAtomicNumber                        43\nElement                     Technetium\nSymbol                              Tc\nAtomicMass                        98.0\nNumberofNeutrons                    55\nNumberofProtons                     43\nNumberofElectrons                   43\nPeriod                               5\nGroup                              7.0\nPhase                       artificial\nRadioactive                        yes\nNatural                            NaN\nMetal                              yes\nNonmetal                           NaN\nMetalloid                          NaN\nType                  Transition Metal\nAtomicRadius                       2.0\nElectronegativity                  1.9\nFirstIonization                   7.28\nDensity                           11.5\nMeltingPoint                   2473.15\nBoilingPoint                    5150.0\nNumberOfIsotopes                  23.0\nDiscoverer           Perrier and Segr�\nYear                            1937.0\nSpecificHeat                       NaN\nNumberofShells                       5\nNumberofValence                    NaN\nName: 42, dtype: object\n```\n:::\n:::\n\n\n## Import\n\n- To save some typing, we'll import it directly.\n\n::: {#65611965 .cell execution_count=45}\n``` {.python .cell-code}\nfrom scipy.interpolate import LinearNDInterpolator\n```\n:::\n\n\n## Data\n\n- We recall electronegativity.\n\n::: {#c81fd984 .cell execution_count=46}\n``` {.python .cell-code code-fold=\"true\"}\n# Plot\nplt.scatter(\n\tx=df[\"Group\"],\n\ty=df[\"Period\"],\n\tc=df[\"Electronegativity\"]\n)\nplt.gca().invert_yaxis()\n# Label\nplt.title(\"Electronegativity\")\nplt.xlabel(\"Group\")\nplt.ylabel(\"Period\")\n_ = plt.colorbar()\n```\n\n::: {.cell-output .cell-output-display}\n![](07_scipy_files/figure-html/cell-47-output-1.png){width=547 height=449}\n:::\n:::\n\n\n## Reference\n\n- The documentation we're following is [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.LinearNDInterpolator.html)\n\n::: {#07d71e37 .cell execution_count=47}\n``` {.python .cell-code code-fold=\"true\"}\nfrom scipy.interpolate import LinearNDInterpolator\nimport numpy as np\nimport matplotlib.pyplot as plt\nrng = np.random.default_rng()\nx = rng.random(10) - 0.5\ny = rng.random(10) - 0.5\nz = np.hypot(x, y)\nX = np.linspace(min(x), max(x))\nY = np.linspace(min(y), max(y))\nX, Y = np.meshgrid(X, Y)  # 2D grid for interpolation\ninterp = LinearNDInterpolator(list(zip(x, y)), z)\nZ = interp(X, Y)\nplt.pcolormesh(X, Y, Z, shading='auto')\nplt.plot(x, y, \"ok\", label=\"input point\")\nplt.legend()\nplt.colorbar()\nplt.axis(\"equal\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](07_scipy_files/figure-html/cell-48-output-1.png){width=561 height=411}\n:::\n:::\n\n\n## Working df\n\n- We need a `df` to work with.\n- We need only Group, Period, Electronegativity\n- We *must not* have any invalid entries.\n- We modify `df` to have only these 3 values, then `.dropna()`\n\n::: {#dcdb4726 .cell execution_count=48}\n``` {.python .cell-code}\ndf = df[[\"Group\", \"Period\", \"Electronegativity\"]]\ndf = df.dropna()\n```\n:::\n\n\n## X \n\n- We will:\n  \t- Determine the input x values.\n\t- We call this `X` (capitalized) to denote it is a vector or array.\n- We used \"Group\" for x.\n\n::: {#4a8ff4b4 .cell execution_count=49}\n``` {.python .cell-code}\nX = df[\"Group\"]\nX[::20]\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```\n0      1.0\n23     6.0\n45    10.0\n80    13.0\nName: Group, dtype: float64\n```\n:::\n:::\n\n\n## Y \n\n- We will:\n  \t- Determine the input x values.\n\t- We call this `Y` (capitalized) to denote it is a vector or array.\n- We used \"Period\" for y.\n\n::: {#93b3a34c .cell execution_count=50}\n``` {.python .cell-code}\nY = df[\"Period\"]\nY[::20]\n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```\n0     1\n23    4\n45    5\n80    6\nName: Period, dtype: int64\n```\n:::\n:::\n\n\n## 2D\n\n- We will:\n  \t- Create the 2D space given `X` and `Y`\n\t- This is a \"column stack\"\n\n::: {#c630029a .cell execution_count=51}\n``` {.python .cell-code}\narr2d = np.column_stack((X,Y))\narr2d[::20]\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```\narray([[ 1.,  1.],\n       [ 6.,  4.],\n       [10.,  5.],\n       [13.,  6.]])\n```\n:::\n:::\n\n\n## Z\n\n- We will:\n  \t- Provide known output values as `Z`\n\n::: {#e521f043 .cell execution_count=52}\n``` {.python .cell-code}\nZ = df[\"Electronegativity\"]\nZ\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```\n0     2.20\n2     0.98\n3     1.57\n4     2.04\n5     2.55\n      ... \n83    2.00\n84    2.20\n86    0.70\n87    0.90\n88    1.10\nName: Electronegativity, Length: 68, dtype: float64\n```\n:::\n:::\n\n\n## SciPy\n\n- Back to SciPy!\n\t- Use `LinearNDInterpolar`\n- It basically makes a function that theoretically described electronegativity.\n\n\n\n## Stop!\n\n\n::: {.callout-note}\n\n- We are about to, essentially, conduct an experiment!\n- We should make a hypothesis first, then test it.\n- First, naively predict Tc's electronegativity, and write down your guess!\n\n:::\n\n- The next slides have my guess, but you should make your own guess first!\n\n\n## My Guess\n\n- I took the electronegativity of Tc's neighbors vertically and horizontally.\n\n::: {#368cb25c .cell execution_count=53}\n``` {.python .cell-code}\nTc\n```\n\n::: {.cell-output .cell-output-display execution_count=53}\n```\nAtomicNumber                        43\nElement                     Technetium\nSymbol                              Tc\nAtomicMass                        98.0\nNumberofNeutrons                    55\nNumberofProtons                     43\nNumberofElectrons                   43\nPeriod                               5\nGroup                              7.0\nPhase                       artificial\nRadioactive                        yes\nNatural                            NaN\nMetal                              yes\nNonmetal                           NaN\nMetalloid                          NaN\nType                  Transition Metal\nAtomicRadius                       2.0\nElectronegativity                  1.9\nFirstIonization                   7.28\nDensity                           11.5\nMeltingPoint                   2473.15\nBoilingPoint                    5150.0\nNumberOfIsotopes                  23.0\nDiscoverer           Perrier and Segr�\nYear                            1937.0\nSpecificHeat                       NaN\nNumberofShells                       5\nNumberofValence                    NaN\nName: 42, dtype: object\n```\n:::\n:::\n\n\n## One Way\n\n- Tc is group 7 and period 5, so, perhaps...\n\n::: {#c596aaba .cell execution_count=54}\n``` {.python .cell-code}\n# DataFrame \"vertical horizontal neighbors\"\nvh = df[df[\"Group\"] >= 6]\nvh = vh[vh[\"Group\"] <= 8]\nvh = vh[vh[\"Period\"] >= 4]\nvh = vh[vh[\"Period\"] <= 6]\nvh\n```\n\n::: {.cell-output .cell-output-display execution_count=54}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Group</th>\n      <th>Period</th>\n      <th>Electronegativity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23</th>\n      <td>6.0</td>\n      <td>4</td>\n      <td>1.66</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>7.0</td>\n      <td>4</td>\n      <td>1.55</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>8.0</td>\n      <td>4</td>\n      <td>1.83</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>6.0</td>\n      <td>5</td>\n      <td>2.16</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>8.0</td>\n      <td>5</td>\n      <td>2.20</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>6.0</td>\n      <td>6</td>\n      <td>2.36</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>7.0</td>\n      <td>6</td>\n      <td>1.90</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>8.0</td>\n      <td>6</td>\n      <td>2.20</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Aside: Boolean Index\n\n- The previous example was not graceful.\n- We can use [Boolean Indexing](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)\n- The range detection method used earlier in `piecewise.py` doesn't work on arrays unfortunately.\n- But `(array < value) & (array > value)` works.\n\n## Aside: Example\n\n::: {#78900ecd .cell execution_count=55}\n``` {.python .cell-code}\nvh = df[(df[\"Group\"] >= 6) & (df[\"Group\"] <= 8) & (df[\"Period\"] >= 4) & (df[\"Period\"] <= 6)]\nvh\n```\n\n::: {.cell-output .cell-output-display execution_count=55}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Group</th>\n      <th>Period</th>\n      <th>Electronegativity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23</th>\n      <td>6.0</td>\n      <td>4</td>\n      <td>1.66</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>7.0</td>\n      <td>4</td>\n      <td>1.55</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>8.0</td>\n      <td>4</td>\n      <td>1.83</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>6.0</td>\n      <td>5</td>\n      <td>2.16</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>8.0</td>\n      <td>5</td>\n      <td>2.20</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>6.0</td>\n      <td>6</td>\n      <td>2.36</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>7.0</td>\n      <td>6</td>\n      <td>1.90</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>8.0</td>\n      <td>6</td>\n      <td>2.20</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Aside: Immediate Neighbor\n\n- It actually probably makes more sense to take\n  \t- The sum, of\n\t- The absolute values, of\n\t- The differences, between\n\t  \t- Tc's group and period, and\n\t\t- The tested row's group and period.\n\n## Immediate Example\n\n::: {#38ddcfc7 .cell execution_count=56}\n``` {.python .cell-code}\nclose = df[(abs(df[\"Group\"] - 7) + abs(df[\"Period\"] - 5)) < 2]\nclose\n```\n\n::: {.cell-output .cell-output-display execution_count=56}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Group</th>\n      <th>Period</th>\n      <th>Electronegativity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>7.0</td>\n      <td>4</td>\n      <td>1.55</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>6.0</td>\n      <td>5</td>\n      <td>2.16</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>8.0</td>\n      <td>5</td>\n      <td>2.20</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>7.0</td>\n      <td>6</td>\n      <td>1.90</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## My Estimate:\n\n- After picking what I thought was things near Tc that should cancel out each other's distance, I calculate their mean.\n\n::: {#695c1c6a .cell execution_count=57}\n``` {.python .cell-code}\nmy_pred = close[\"Electronegativity\"].mean()\nmy_pred\n```\n\n::: {.cell-output .cell-output-display execution_count=57}\n```\nnp.float64(1.9525000000000001)\n```\n:::\n:::\n\n\n- This is my naive prediction.\n- Now I interpolate.\n\n## Interpolate\n\n- `LinearNDInterpolator` takes an array of known inputs and an array of known outputs and returns a function that it thinks describes the relationship.\n- \"Thinks\" being a vague term here to convey a sense of learning or prediction or estimation.\n\n::: {#81e986ac .cell execution_count=58}\n``` {.python .cell-code}\nf = LinearNDInterpolator(arr2d, Z)\nscipy_pred = f(7,5)\n[scipy_pred, my_pred, Tc[\"Electronegativity\"]]\n```\n\n::: {.cell-output .cell-output-display execution_count=58}\n```\n[array(1.725), np.float64(1.9525000000000001), np.float64(1.9)]\n```\n:::\n:::\n\n\n## Exercise\n\n- Predict using your own methods the density of Tc.\n- Interpolate using SciPy the density of Tc.\n\n## Solution\n\n::: {#ea6acb42 .cell execution_count=59}\n``` {.python .cell-code code-fold=\"true\"}\ndf = pd.read_csv(\"https://gist.githubusercontent.com/GoodmanSciences/c2dd862cd38f21b0ad36b8f96b4bf1ee/raw/1d92663004489a5b6926e944c1b3d9ec5c40900e/Periodic%2520Table%2520of%2520Elements.csv\")\ndf.drop(42)\ndf = df[[\"Group\", \"Period\", \"Density\"]]\ndf = df.dropna()\nf = LinearNDInterpolator(np.column_stack((df[\"Group\"],df[\"Period\"])), df[\"Density\"])\nme = df[(abs(df[\"Group\"] - 7) + abs(df[\"Period\"] - 5)) < 2][\"Density\"].mean()\n[f(7,5), me, Tc[\"Density\"]]\n```\n:::\n\n\n",
    "supporting": [
      "07_scipy_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}