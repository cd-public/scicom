{
  "hash": "7cac37eb8255419e3b8d77d13eb81e9f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Sklearn \n---\n\n\n\n\n\n\n# What is Sklearn?{.smaller}\n\n- `Sklearn` or `scikit-learn`, originally conceived as an extension to SciPy.\n\n> [Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities.Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities.](https://scikit-learn.org/stable/getting_started.html)\n\n## Why sklearn? \n\n* \"Simple and efficient tools for predictive data analysis\"\n* \"Accessible to everybody, and reusable in various contexts\"\n* \"Built on NumPy, SciPy, and matplotlib\"\n* \"Open source, commercially usable - BSD license\"\n\n## Why not sklearn?\n\n- The closest thing to competitors, to my knowledge, are Torch and Tensorflow.\n  - The Meta and Google GPU-accelerated frameworks, respectively.\n- I don't like that the other frameworks are managed by big tech companies, and I don't think they are as well suited to science.\n\n## Using Sklearn\n\n- Sklearn/scikit-learn is incrementally more involved to install via `pip` because, well, sometimes it is called \"sklearn\" and sometimes \"scikit-learn\".\n- This gets me almost every time:\n```{.bash code-line-numbers=\"false\"}\n$ python3 -m pip install sklearn\nCollecting sklearn\n  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n  Preparing metadata (setup.py) ... error\n  error: subprocess-exited-with-error\n\n  × python setup.py egg_info did not run successfully.\n  │ exit code: 1\n  ╰─> [15 lines of output]\n      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n      rather than 'sklearn' for pip commands.\n```\n\n## Use `scikit-learn`\n\n- Scikit-learn recommends the following:\n```{.bash code-line-numbers=\"false\"}\npython3 -m pip install scikit-learn\npython3 -m pip show scikit-learn  # show scikit-learn version and location\npython3 -m pip freeze             # show all installed packages in the environment\npython3 -c \"import sklearn; sklearn.show_versions()\"\n```\n- You will see *a lot* of text.\n\n## Easier\n\n- Just open `python`/`python3` and \n\n::: {#22d5c979 .cell execution_count=1}\n``` {.python .cell-code}\nimport sklearn\n```\n:::\n\n\n- Like SciPy, usually *parts* of Sklearn are imported, so that isn't an expected two-letter name like `np` or `pd`\n- I *never* use sklearn without at least **pandas**, NumPy, and Matplotlib.\n\n::: {#52196fdb .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n## These Slides\n\n- We will focus on *cognitive* and *vision* science, motivated by the legendary example that drove early machine learning research...\n\n# [THE MNIST DATABASE](https://web.archive.org/web/20200430193701/http://yann.lecun.com/exdb/mnist/)\n\nof handwritten digits\n\n## Citation\n\n```{.LaTeX filename=\"mnist.bib\" code-line-numbers=\"false\"}\n@article{lecun1998mnist,\n  title={The MNIST database of handwritten digits},\n  author={LeCun, Yann},\n  journal={http://yann. lecun. com/exdb/mnist/},\n  year={1998}\n}\n```\n\n## Credit\n\n- I will follow this guide:\n- [Recognizing hand-written digits](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html)\n\n## The Data\n\n- The MNIST dataset is pretty easy to find, even if the original source isn't maintained anymore.\n- In fairness, it was posted before *I* started **kindergarten**\n  \t- German for \"children garden\"\n- It is so much everywhere, it is built into sklearn!\n\n::: {#147eac66 .cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn import datasets\n\ndigits = datasets.load_digits()\n```\n:::\n\n\n## Look at it\n\n::: {#99af3653 .cell execution_count=4}\n``` {.python .cell-code}\ndigits\n```\n\n::: {.cell-output .cell-output-display execution_count=1911}\n```\n{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n        ...,\n        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n 'target': array([0, 1, 2, ..., 8, 9, 8]),\n 'frame': None,\n 'feature_names': ['pixel_0_0',\n  'pixel_0_1',\n  'pixel_0_2',\n  'pixel_0_3',\n  'pixel_0_4',\n  'pixel_0_5',\n  'pixel_0_6',\n  'pixel_0_7',\n  'pixel_1_0',\n  'pixel_1_1',\n  'pixel_1_2',\n  'pixel_1_3',\n  'pixel_1_4',\n  'pixel_1_5',\n  'pixel_1_6',\n  'pixel_1_7',\n  'pixel_2_0',\n  'pixel_2_1',\n  'pixel_2_2',\n  'pixel_2_3',\n  'pixel_2_4',\n  'pixel_2_5',\n  'pixel_2_6',\n  'pixel_2_7',\n  'pixel_3_0',\n  'pixel_3_1',\n  'pixel_3_2',\n  'pixel_3_3',\n  'pixel_3_4',\n  'pixel_3_5',\n  'pixel_3_6',\n  'pixel_3_7',\n  'pixel_4_0',\n  'pixel_4_1',\n  'pixel_4_2',\n  'pixel_4_3',\n  'pixel_4_4',\n  'pixel_4_5',\n  'pixel_4_6',\n  'pixel_4_7',\n  'pixel_5_0',\n  'pixel_5_1',\n  'pixel_5_2',\n  'pixel_5_3',\n  'pixel_5_4',\n  'pixel_5_5',\n  'pixel_5_6',\n  'pixel_5_7',\n  'pixel_6_0',\n  'pixel_6_1',\n  'pixel_6_2',\n  'pixel_6_3',\n  'pixel_6_4',\n  'pixel_6_5',\n  'pixel_6_6',\n  'pixel_6_7',\n  'pixel_7_0',\n  'pixel_7_1',\n  'pixel_7_2',\n  'pixel_7_3',\n  'pixel_7_4',\n  'pixel_7_5',\n  'pixel_7_6',\n  'pixel_7_7'],\n 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n         ...,\n         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n \n        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n         ...,\n         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n \n        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n         ...,\n         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n \n        ...,\n \n        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n         ...,\n         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n \n        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n         ...,\n         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n \n        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n         ...,\n         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 1797\\n:Number of Attributes: 64\\n:Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n:Missing Attribute Values: None\\n:Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n:Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. dropdown:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}\n```\n:::\n:::\n\n\n## Okay\n\n- `digits` is a \"bunch\", which I'd never actually heard of before in my life, but appears almost identical to a Python `dict` or \"dictionary.\n\n::: {#1a182de1 .cell execution_count=5}\n``` {.python .cell-code}\ntype(digits)\n```\n\n::: {.cell-output .cell-output-display execution_count=1912}\n```\nsklearn.utils._bunch.Bunch\n```\n:::\n:::\n\n\n- Here's a `dict`\n\n::: {#434f52f7 .cell execution_count=6}\n``` {.python .cell-code}\nd = {\"data\" : np.arange(10), \"target\" : np.arange(10), \"frame\" : None}\ntype(d)\n```\n\n::: {.cell-output .cell-output-display execution_count=1913}\n```\ndict\n```\n:::\n:::\n\n\n# Dictionaries\n\n## What is a Dictionary?\n\n- A dictionary is a built-in Python data type used to store collections of data.\n- It stores data in \"key-value\" pairs.\n- Dictionaries are unordered, mutable (like lists, not like tuples), and indexed by *keys*.\n\n::: {#404aa0fc .cell execution_count=7}\n``` {.python .cell-code}\nmy_dict = {\"one\": 1, \"two\": 2, \"three\": 3}\nprint(my_dict)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'one': 1, 'two': 2, 'three': 3}\n```\n:::\n:::\n\n\n## Key-Value Storage\n\n- Each item in a dictionary consists of a *key* and its corresponding *value*.\n- **Keys** must be unique and immutable (e.g., strings, numbers, tuples).\n  \t- Cannot be lists!\n- **Values** can be of any data type and can be duplicated.\n\n::: {#a9d2a5c5 .cell execution_count=8}\n``` {.python .cell-code}\nnumber_strings = {1: \"one\", 2: \"two\", 11: \"eleven\", 20: \"twenty\"}\nnumber_strings[11], number_strings[2]\n```\n\n::: {.cell-output .cell-output-display execution_count=1915}\n```\n('eleven', 'two')\n```\n:::\n:::\n\n\n## Why dictionaries?\n\n- Think of a physical dictionary: a \"key\" (the word) points to a \"value\" (its definition).\n- Python dictionaries work similarly, storing unique keys that retrieve associated values.\n- This structure is powerful for organizing data where each piece needs a distinct label.\n\n::: {#7f871b8e .cell execution_count=9}\n``` {.python .cell-code}\nmeanings = {\"earth\": \"ground, soil, land\", \"wind\": \"air in natural motion\", \"fire\": \"combustion or burning\", \"water\": \"colorless, transparent, odorless liquid\"}\nmeanings[\"earth\"]\n```\n\n::: {.cell-output .cell-output-display execution_count=1916}\n```\n'ground, soil, land'\n```\n:::\n:::\n\n\n## Accessing Values\n\n- Values are accessed by referring to their associated key.\n- You can use square brackets `[]` or the `.get()` method.\n- `.get()` returns `None` or a default value if the key is not found, preventing errors.\n\n::: {#79add034 .cell execution_count=10}\n``` {.python .cell-code}\nmy_dict = {\"apple\": \"red\", \"banana\": \"yellow\"}\nmy_dict[\"apple\"], my_dict.get(\"strawberry\", \"idk\")\n```\n\n::: {.cell-output .cell-output-display execution_count=1917}\n```\n('red', 'idk')\n```\n:::\n:::\n\n\n## Adding and Updating Items\n\n- New key-value pairs can be added by assigning a value to a new key.\n- Existing values can be updated by assigning a new value to an existing key.\n\n::: {#2d95b9d9 .cell execution_count=11}\n``` {.python .cell-code}\nmy_dict = {\"name\": \"Alice\"}\nmy_dict[\"age\"] = 30\nmy_dict[\"name\"] = \"Bob\"\nmy_dict\n```\n\n::: {.cell-output .cell-output-display execution_count=1918}\n```\n{'name': 'Bob', 'age': 30}\n```\n:::\n:::\n\n\n## Deleting Items\n\n- Items can be removed using the `del` keyword or the `.pop()` method.\n- `.pop()` also returns the value of the removed item.\n\n::: {#dd9a35de .cell execution_count=12}\n``` {.python .cell-code}\nmy_dict = {\"a\": 1, \"b\": 2, \"c\": 3}\ndel my_dict[\"a\"]\nmy_dict.pop(\"b\")\n```\n\n::: {.cell-output .cell-output-display execution_count=1919}\n```\n2\n```\n:::\n:::\n\n\n- Also check `my_dict`:\n\n::: {#164a2eee .cell execution_count=13}\n``` {.python .cell-code}\nmy_dict\n```\n\n::: {.cell-output .cell-output-display execution_count=1920}\n```\n{'c': 3}\n```\n:::\n:::\n\n\n## NumPy Arrays\n\n- While `np.ndarray` is a homogeneous data structure, dictionaries can store heterogeneous data.\n- Dictionaries can be used to organize parameters or metadata associated with NumPy arrays.\n\n::: {#953b006a .cell execution_count=14}\n``` {.python .cell-code}\ndata_info = {\"name\": \"Measurements\", \"unit\": \"meters\", \"data\": np.array([10.1, 12.5, 11.3])}\ndata_info[\"data\"].mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=1921}\n```\nnp.float64(11.300000000000002)\n```\n:::\n:::\n\n\n## **pandas** DataFrames\n\n- Dictionaries are commonly used to create `pd.DataFrame` objects.\n- Keys become column names, and values (lists or arrays) become column data.\n- This provides a natural way to structure tabular data before DataFrame creation.\n\n::: {#df3e3a56 .cell execution_count=15}\n``` {.python .cell-code}\nimport pandas as pd\ndata = {\n    \"City\": [\"Portland\", \"Seattle\", \"Boise\"],\n    \"Population\": [650000, 750000, 230000],\n    \"State\": [\"OR\", \"WA\", \"ID\"]\n}\npd.DataFrame(data)\n```\n\n::: {.cell-output .cell-output-display execution_count=1922}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>City</th>\n      <th>Population</th>\n      <th>State</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Portland</td>\n      <td>650000</td>\n      <td>OR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Seattle</td>\n      <td>750000</td>\n      <td>WA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Boise</td>\n      <td>230000</td>\n      <td>ID</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## DataFrame Column Selection\n\n- Dictionaries can be used to map original column names to new, more descriptive names.\n- This is useful for renaming columns in a `pd.DataFrame`.\n\n::: {#19969c06 .cell execution_count=16}\n``` {.python .cell-code}\ndf = pd.DataFrame({'col_a': [1,2], 'col_b': [3,4]})\ncolumn_rename_map = {'col_a': 'Feature_1', 'col_b': 'Feature_2'}\ndf.rename(columns=column_rename_map)\n```\n\n::: {.cell-output .cell-output-display execution_count=1923}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature_1</th>\n      <th>Feature_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## In sklearn\n\n- Dictionaries are fundamental for defining model parameters (hyperparameters) in `sklearn`.\n- They are used in `GridSearchCV` or `RandomizedSearchCV` to specify parameter grids for tuning.\n\n::: {#0df76ee1 .cell execution_count=17}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LogisticRegression\nparams = {\"penalty\": \"l1\", \"C\": 0.1, \"solver\": \"liblinear\"}\nmodel = LogisticRegression(**params)\nmodel.get_params()\n```\n\n::: {.cell-output .cell-output-display execution_count=1924}\n```\n{'C': 0.1,\n 'class_weight': None,\n 'dual': False,\n 'fit_intercept': True,\n 'intercept_scaling': 1,\n 'l1_ratio': None,\n 'max_iter': 100,\n 'multi_class': 'deprecated',\n 'n_jobs': None,\n 'penalty': 'l1',\n 'random_state': None,\n 'solver': 'liblinear',\n 'tol': 0.0001,\n 'verbose': 0,\n 'warm_start': False}\n```\n:::\n:::\n\n\n## Model Configuration\n\n- Dictionaries can store various configuration settings for an `sklearn` pipeline or model.\n- This makes configurations easily readable, modifiable, and transportable.\n\n::: {#5a8f05bc .cell execution_count=18}\n``` {.python .cell-code}\nmodel_config = {\n    \"model_type\": \"RandomForestClassifier\",\n    \"n_estimators\": 100,\n    \"max_depth\": 10,\n    \"random_state\": 42\n}\nprint(f\"Model Type: {model_config['model_type']}\")\nprint(f\"Number of Estimators: {model_config['n_estimators']}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel Type: RandomForestClassifier\nNumber of Estimators: 100\n```\n:::\n:::\n\n\n## Aside: f-Strings (Format Strings)\n\n- f-strings offer a concise and readable way to embed Python expressions inside string literals.\n- They are prefixed with an `f` (or `F`) and use curly braces `{}` to contain expressions.\n- This feature, introduced in Python 3.6, makes string formatting much more straightforward.\n\n::: {#7fd3318b .cell execution_count=19}\n``` {.python .cell-code}\nmodel_config = {\"model_type\": \"LogisticRegression\", \"n_estimators\": 100}\nprint(f\"Model Type: {model_config['model_type']}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel Type: LogisticRegression\n```\n:::\n:::\n\n\n## Why Use f-Strings?\n\n- **Readability**: The expressions are right within the string, making it easy to see what's being formatted.\n- **Conciseness**: Less boilerplate code compared to older formatting methods like `.format()` or `%`.\n- **Performance**: Generally faster than other string formatting methods.\n\n::: {#fe33ae36 .cell execution_count=20}\n``` {.python .cell-code}\nmy_name = \"Alice\"\nmy_age = 30\nprint(f\"Hello, my name is {my_name} and I am {my_age} years old.\")\nprint(f\"Number of Estimators: {model_config['n_estimators']}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello, my name is Alice and I am 30 years old.\nNumber of Estimators: 100\n```\n:::\n:::\n\n\n## Feature Store\n\n- Dictionaries can temporarily hold features for a single sample before passing to a model.\n- This is particularly useful when working with `DictVectorizer` in text processing.\n\n::: {#90f461ae .cell execution_count=21}\n``` {.python .cell-code}\nfrom sklearn.feature_extraction import DictVectorizer\ndata = [{\"color\": \"red\", \"size\": \"small\"}, {\"color\": \"blue\", \"size\": \"large\"}]\nvec = DictVectorizer(sparse=False)\nfeatures = vec.fit_transform(data)\nprint(features)\nprint(vec.get_feature_names_out())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[0. 1. 0. 1.]\n [1. 0. 1. 0.]]\n['color=blue' 'color=red' 'size=large' 'size=small']\n```\n:::\n:::\n\n\n## Key Takeaways\n\n- Dictionaries provide flexible key-value storage for diverse data.\n- They are crucial for organizing data, especially when converting to `pd.DataFrame`.\n- In `sklearn`, dictionaries are indispensable for hyperparameter tuning and model configuration, making your machine learning workflows more organized and reproducible.\n\n\n# The Dataset\n\n## MNIST\n\n- Basically, MNIST contains:\n  - Handwritten digits from government forms\n  - What digit someone thought the person was trying to write.\n- We will:\n  - Try to get a computer to do this work for us.\n- Let's look at an example.\n\n## \"target\"\n\n- \"target\" gives what a human *thought* the digit was.\n- It is generally regard that whoever set the targets was mostly correct.\n- The first ten digits are thought to be:\n\n::: {#b8044b4c .cell execution_count=22}\n``` {.python .cell-code}\ndigits[\"target\"][:10]\n```\n\n::: {.cell-output .cell-output-display execution_count=1929}\n```\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n```\n:::\n:::\n\n\n## \"images\"\n\n- \"images\" are more complicated.\n- Let's take a look at just the initial image:\n\n::: {#791c632a .cell execution_count=23}\n``` {.python .cell-code}\nim = digits[\"images\"][0]\nim\n```\n\n::: {.cell-output .cell-output-display execution_count=1930}\n```\narray([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])\n```\n:::\n:::\n\n\n## Examine\n\n::: {#9db8bd50 .cell execution_count=24}\n``` {.python .cell-code}\nim.shape, im.size, im.ndim\n```\n\n::: {.cell-output .cell-output-display execution_count=1931}\n```\n((8, 8), 64, 2)\n```\n:::\n:::\n\n\n::: {#d1e6829d .cell execution_count=25}\n``` {.python .cell-code}\nim.mean(), im.max()\n```\n\n::: {.cell-output .cell-output-display execution_count=1932}\n```\n(np.float64(4.59375), np.float64(15.0))\n```\n:::\n:::\n\n\n::: {#9114dbcd .cell execution_count=26}\n``` {.python .cell-code}\ndigits[\"images\"].mean(), digits[\"images\"].max()\n```\n\n::: {.cell-output .cell-output-display execution_count=1933}\n```\n(np.float64(4.884164579855314), np.float64(16.0))\n```\n:::\n:::\n\n\n## Takeways\n\n- `im` is an 8-by-8 array of values from 0 to 16\n\n::: {#12764d01 .cell execution_count=27}\n``` {.python .cell-code}\nplt.imshow(im)\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-28-output-1.png){width=407 height=411}\n:::\n:::\n\n\n## Coloration\n\n::: {#6f06416b .cell execution_count=28}\n``` {.python .cell-code}\nplt.imshow(im)\nplt.colorbar()\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-29-output-1.png){width=489 height=411}\n:::\n:::\n\n\n- Might be easier in grayscale.\n\n## cmap\n\n- Matplotlib provides colormaps we can specify.\n  - I say a `'Greys'` in there.\n\n::: {#093fe2e3 .cell execution_count=29}\n``` {.python .cell-code}\nfrom matplotlib import colormaps\nlist(colormaps)[:20]\n```\n\n::: {.cell-output .cell-output-display execution_count=1936}\n```\n['magma',\n 'inferno',\n 'plasma',\n 'viridis',\n 'cividis',\n 'twilight',\n 'twilight_shifted',\n 'turbo',\n 'Blues',\n 'BrBG',\n 'BuGn',\n 'BuPu',\n 'CMRmap',\n 'GnBu',\n 'Greens',\n 'Greys',\n 'OrRd',\n 'Oranges',\n 'PRGn',\n 'PiYG']\n```\n:::\n:::\n\n\n## Greyscale\n\n::: {#2eed004a .cell execution_count=30}\n``` {.python .cell-code}\nplt.imshow(im, cmap='Greys')\nplt.colorbar()\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-31-output-1.png){width=489 height=411}\n:::\n:::\n\n\n## Interpolation\n\n- Use an interpolater (`'spline16'` looked good).\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {#f4c7f655 .cell execution_count=31}\n``` {.python .cell-code}\nplt.imshow(im) # I am writing a comment here to align vertically\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-32-output-1.png){width=407 height=411}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#1d371ded .cell execution_count=32}\n``` {.python .cell-code}\nplt.imshow(im, cmap='Greys', interpolation=\"spline16\")\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-33-output-1.png){width=407 height=411}\n:::\n:::\n\n\n:::\n\n::::\n\n\n## It's a zero \n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {#10309e64 .cell execution_count=33}\n``` {.python .cell-code}\ndigits[\"target\"][0]\n```\n\n::: {.cell-output .cell-output-display execution_count=1940}\n```\nnp.int64(0)\n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#4101ffc0 .cell execution_count=34}\n``` {.python .cell-code}\nplt.imshow(digits[\"images\"][0], cmap='Greys', interpolation=\"spline16\")\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-35-output-1.png){width=407 height=411}\n:::\n:::\n\n\n:::\n\n::::\n\n## Look at more\n\n- Write a function to check some images out.\n\n::: {#2d120349 .cell execution_count=35}\n``` {.python .cell-code}\ndef see_im(n):\n\tplt.imshow(digits[\"images\"][n], cmap='Greys', interpolation='spline16')\n\tplt.axis('off') # Just looked up how to remove axes\n\tplt.title(digits[\"target\"][n])\n\tplt.show() # Like print, for images, or you can save\n```\n:::\n\n\n- Wait how many do I have?\n\n::: {#2d188b24 .cell execution_count=36}\n``` {.python .cell-code}\ndigits[\"target\"].shape\n```\n\n::: {.cell-output .cell-output-display execution_count=1943}\n```\n(1797,)\n```\n:::\n:::\n\n\n## See More\n\n:::: {.columns}\n\n::: {.column width=\"33%\"}\n\n::: {#a3b4d98b .cell execution_count=37}\n``` {.python .cell-code}\nsee_im(10)\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-38-output-1.png){width=389 height=409}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"33%\"}\n\n::: {#5aaa8e70 .cell execution_count=38}\n``` {.python .cell-code}\nsee_im(100)\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-39-output-1.png){width=389 height=409}\n:::\n:::\n\n\n:::\n\n\n::: {.column width=\"33%\"}\n\n::: {#c1a0ad0e .cell execution_count=39}\n``` {.python .cell-code}\nsee_im(1000)\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-40-output-1.png){width=389 height=409}\n:::\n:::\n\n\n:::\n\n::::\n\n\n# Classification\n\n## Classification\n\n> [Classification is the activity of assigning objects to some pre-existing classes or categories. This is distinct from the task of establishing the classes themselves (for example through cluster analysis). Examples include diagnostic tests, identifying spam emails and deciding whether to give someone a driving license.](https://en.wikipedia.org/wiki/Classification)\n\n## Flatten\n\n- We, as humans, recognize that those things look a lot like images.\n- But the images are 3D array, which is more more annoying to work with than one-row-per-digit.\n- To begin, we \"flatten\" to 2D images into 1D arrays.\n- We want `1794` arrays of length `64` (was: 8-by-8)\n\n## Reshape\n\n- We use NumPy `.reshape`\n\n::: {#dc2c3bb5 .cell execution_count=40}\n``` {.python .cell-code}\ncount = len(digits[\"images\"])\ndata = digits[\"images\"].reshape(count, 64)\ndata[:3]\n```\n\n::: {.cell-output .cell-output-display execution_count=1947}\n```\narray([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n        15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n        12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n         0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n        10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.],\n       [ 0.,  0.,  0., 12., 13.,  5.,  0.,  0.,  0.,  0.,  0., 11., 16.,\n         9.,  0.,  0.,  0.,  0.,  3., 15., 16.,  6.,  0.,  0.,  0.,  7.,\n        15., 16., 16.,  2.,  0.,  0.,  0.,  0.,  1., 16., 16.,  3.,  0.,\n         0.,  0.,  0.,  1., 16., 16.,  6.,  0.,  0.,  0.,  0.,  1., 16.,\n        16.,  6.,  0.,  0.,  0.,  0.,  0., 11., 16., 10.,  0.,  0.],\n       [ 0.,  0.,  0.,  4., 15., 12.,  0.,  0.,  0.,  0.,  3., 16., 15.,\n        14.,  0.,  0.,  0.,  0.,  8., 13.,  8., 16.,  0.,  0.,  0.,  0.,\n         1.,  6., 15., 11.,  0.,  0.,  0.,  1.,  8., 13., 15.,  1.,  0.,\n         0.,  0.,  9., 16., 16.,  5.,  0.,  0.,  0.,  0.,  3., 13., 16.,\n        16., 11.,  5.,  0.,  0.,  0.,  0.,  3., 11., 16.,  9.,  0.]])\n```\n:::\n:::\n\n\n## Models\n\n- Foundation to the notion of machine learning is *training* and *testing*.\n  \t- More properly to *supervised* machine learning, but more on that latter.\n- Specifically, using training data, we will set the coefficients and parameters of a model, which we can think of as a function with a number of parameters.\n\n## Splits\n\n- We split up our data, and\n  \t- Some data we use to *train* a model.\n\t  \t- Basically, find coefficients of a function.\n\t- Some data we use to *test* a classifier\n\t  \t- Compare model to actual.\n\n# Supervised Learning\n\n## Train-Test Split\n\n- The **training set** is used to teach our model to identify patterns and relationships.\n- The **testing set** is held-out to evaluate the trained model on new, unseen data.\n\n::: {#f47a054f .cell execution_count=41}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\ny = np.array([0, 1, 0, 1])\n\n# Train on 75%, test on 25% by default\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nX_test, y_test\n```\n\n::: {.cell-output .cell-output-display execution_count=1948}\n```\n(array([[7, 8]]), array([1]))\n```\n:::\n:::\n\n\n## Supervised Learning\n\n- **Supervised learning** is a type of machine learning where the algorithm learns from **labeled data**.\n- Labeled data consists of input features (`X`) and corresponding outcomes (`y`).\n\n::: {#6273d083 .cell execution_count=42}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\n\n# Example labeled data (house size in sqft, price in $1000s)\nX_train = np.array([[1000], [1500], [1200], [1800]])\ny_train = np.array([200, 300, 240, 360])\n\nmodel = LinearRegression()\n_ = model.fit(X_train, y_train) # The \"supervision\" happens here\n```\n:::\n\n\n## Models and Coefficients\n\n- A **model** represents the learned relationship inputs-to-targets \n- Sometimes this relationship is expressed through **coefficients**.\n- Change in the target a unit change in input feature with other features constant.\n\n::: {#c32a9678 .cell execution_count=43}\n``` {.python .cell-code}\n# The model learns the equation: price = coefficient * size + intercept\nmodel.coef_, model.intercept_\n```\n\n::: {.cell-output .cell-output-display execution_count=1950}\n```\n(array([0.2]), np.float64(-5.684341886080802e-14))\n```\n:::\n:::\n\n\n## Higher Dimensions\n\n- With multiple input features, each has a **coefficient**.\n- The sign and magnitude of each coefficient show the influence of a feature.\n\n::: {#10b776f2 .cell execution_count=44}\n``` {.python .cell-code}\nd = {'size': [1000, 1500, 1200, 1800], 'bedrooms': [2, 3, 2, 4], 'price': [200, 300, 240, 360]}\ndf = pd.DataFrame(d)\nX_train, y_train = df[['size', 'bedrooms']], df['price']\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\nmodel.coef_, model.intercept_\n```\n\n::: {.cell-output .cell-output-display execution_count=1951}\n```\n(array([ 2.00000000e-01, -1.32379986e-14]), np.float64(0.0))\n```\n:::\n:::\n\n\n## The Digits\n\n- We can train/test split the digits like so:\n\n::: {#14a0a6c0 .cell execution_count=45}\n``` {.python .cell-code}\n# Recall we \"flattened\" images into \"data\"\nX_train, X_test, y_train, y_test = train_test_split(data, digits[\"target\"])\n```\n:::\n\n\n# Classifiers\n\n## Perceptron \n\n- We use a *perceptron*, one of the oldest and most famous machine learning frameworks.\n\n> The artificial neuron network was invented in 1943 by Warren McCulloch and Walter Pitts in A logical calculus of the ideas immanent in nervous activity.\n\n- Described visually in textbooks in [1958](https://commons.wikimedia.org/wiki/File:Organization_of_a_biological_brain_and_a_perceptron.png)\n- Inspired by neuroscience ideas of the time.\n \n\n##\n\n<center>\n<img width=\"70%\" style=\"filter:invert(.9)\" src=\"https://upload.wikimedia.org/wikipedia/commons/0/08/Organization_of_a_biological_brain_and_a_perceptron.png\"></img>\n</center>\n\n## Import\n\n- Import and create a perceptron.\n\n::: {#16db72df .cell execution_count=46}\n``` {.python .cell-code}\nfrom sklearn.linear_model import Perceptron\nclf = Perceptron() # This will be the model that will contain coefficients\nclf # At first, not fitted to anything!\n```\n\n::: {.cell-output .cell-output-display execution_count=1953}\n```{=html}\n<style>#sk-container-id-59 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: #000;\n  --sklearn-color-text-muted: #666;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-59 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-59 pre {\n  padding: 0;\n}\n\n#sk-container-id-59 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-59 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-59 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-59 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-59 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-59 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-59 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-59 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-59 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-59 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-59 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-59 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-59 label.sk-toggleable__label {\n  cursor: pointer;\n  display: flex;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n  align-items: start;\n  justify-content: space-between;\n  gap: 0.5em;\n}\n\n#sk-container-id-59 label.sk-toggleable__label .caption {\n  font-size: 0.6rem;\n  font-weight: lighter;\n  color: var(--sklearn-color-text-muted);\n}\n\n#sk-container-id-59 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-59 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-59 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-59 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-59 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-59 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-59 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-59 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-59 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-59 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-59 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-59 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-59 div.sk-label label.sk-toggleable__label,\n#sk-container-id-59 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-59 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-59 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-59 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-59 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-59 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-59 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-59 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-59 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 0.5em;\n  text-align: center;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-59 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-59 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-59 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-59 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-59\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" checked><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>Perceptron</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.Perceptron.html\">?<span>Documentation for Perceptron</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>Perceptron()</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\n## Training\n\n- We train or `.fit()` the model to the data.\n\n::: {#86cae3ad .cell execution_count=47}\n``` {.python .cell-code}\nclf.fit(X_train, y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=1954}\n```{=html}\n<style>#sk-container-id-60 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: #000;\n  --sklearn-color-text-muted: #666;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-60 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-60 pre {\n  padding: 0;\n}\n\n#sk-container-id-60 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-60 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-60 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-60 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-60 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-60 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-60 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-60 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-60 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-60 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-60 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-60 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-60 label.sk-toggleable__label {\n  cursor: pointer;\n  display: flex;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n  align-items: start;\n  justify-content: space-between;\n  gap: 0.5em;\n}\n\n#sk-container-id-60 label.sk-toggleable__label .caption {\n  font-size: 0.6rem;\n  font-weight: lighter;\n  color: var(--sklearn-color-text-muted);\n}\n\n#sk-container-id-60 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-60 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-60 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-60 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-60 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-60 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-60 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-60 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-60 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-60 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-60 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-60 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-60 div.sk-label label.sk-toggleable__label,\n#sk-container-id-60 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-60 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-60 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-60 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-60 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-60 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-60 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-60 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-60 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 0.5em;\n  text-align: center;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-60 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-60 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-60 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-60 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-60\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" checked><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Perceptron</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.Perceptron.html\">?<span>Documentation for Perceptron</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Perceptron()</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\n- Then we can predict over the testing set!\n\n::: {#e0abf840 .cell execution_count=48}\n``` {.python .cell-code}\ny_pred = clf.predict(X_test)\ny_pred[:10], y_test[:10]\n```\n\n::: {.cell-output .cell-output-display execution_count=1955}\n```\n(array([7, 7, 6, 8, 5, 2, 3, 3, 9, 3]), array([7, 9, 6, 8, 5, 2, 3, 3, 9, 3]))\n```\n:::\n:::\n\n\n## Not bad!\n\n- More detailed reporting from `metrics`\n\n::: {#db679243 .cell execution_count=49}\n``` {.python .cell-code}\nfrom sklearn import metrics\n\n# We print so it looks a bit nicer\nprint(metrics.classification_report(y_test, y_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n           0       1.00      0.98      0.99        48\n           1       1.00      0.79      0.88        47\n           2       0.98      0.98      0.98        49\n           3       1.00      0.84      0.91        43\n           4       1.00      0.98      0.99        50\n           5       0.93      0.98      0.95        51\n           6       1.00      1.00      1.00        34\n           7       0.92      1.00      0.96        47\n           8       0.73      1.00      0.84        46\n           9       0.97      0.83      0.89        35\n\n    accuracy                           0.94       450\n   macro avg       0.95      0.94      0.94       450\nweighted avg       0.95      0.94      0.94       450\n\n```\n:::\n:::\n\n\n## Where did we miss?\n\n- We can see what we got wrong.\n\n::: {#237d6fc1 .cell execution_count=50}\n``` {.python .cell-code}\n# That [0] prevents us from getting tuple of length 1\nmisses = np.where(y_test != y_pred)[0]\nmisses\n```\n\n::: {.cell-output .cell-output-display execution_count=1957}\n```\narray([  1,  34,  69,  81, 106, 110, 127, 134, 136, 165, 168, 207, 223,\n       249, 255, 314, 321, 322, 346, 367, 379, 387, 390, 406, 433, 438,\n       444])\n```\n:::\n:::\n\n\n- Let's look at the first two of those.\n\n## Two Misses\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {#83bdd5b9 .cell execution_count=51}\n``` {.python .cell-code}\ni = misses[0]\nprint(y_test[i], y_pred[i])\nplt.imshow(X_test[i].reshape((8,8)), cmap=\"Greys\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n9 7\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-52-output-2.png){width=407 height=411}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#91013a44 .cell execution_count=52}\n``` {.python .cell-code}\ni = misses[1]\nprint(y_test[i], y_pred[i])\nplt.imshow(X_test[i].reshape((8,8)), cmap=\"Greys\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1 8\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-53-output-2.png){width=407 height=411}\n:::\n:::\n\n\n:::\n\n::::\n\n## On Accuracy\n\n- Machine learning frameworks were doing better than I could do around ~2010\n- On these older datasets with:\n  \t- Greyscale\n\t- 16 color\n\t- 64 pixel\n- Maybe your eyes are better than the perceptron, but mine aren't!\n\n# Clustering\n\n## Unsupervised Learning\n\n- **Unsupervised learning** deals with unlabeled data, where there are no predefined target variables (`y`).\n- Find hidden patterns, structures, or relationships within the data itself.\n\n## Clustering\n\n- **Clustering** is an unsupervised learning task that groups data points into clusters based on their similarity.\n- Data points within the same cluster are more similar to each other than to those in other clusters.\n- The goal is to discover natural groupings in the data without any prior knowledge of those groups.\n\n\n## $k$-means Clustering\n\n- **$k$-means clustering** is a popular partitioning algorithm that divides data into `k` predefined clusters.\n- It aims to minimize the sum of squared distances between data points and their assigned cluster's centroid.\n- The `k` parameter (number of clusters) must be specified in advance.\n\n::: {#739f7462 .cell execution_count=53}\n``` {.python .cell-code}\nfrom sklearn.cluster import KMeans\n\nX = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])\nmodel = KMeans(2) # 2 \"clusters\"\n```\n:::\n\n\n## How $k$-means Works \n\n- **Start**: $k$ data points as cluster centroids.\n- **Assign**: To the cluster with closest center.\n- **Update**: Recalculate the cluster mean.\n- **Repeat**: Until the assignments no longer change.\n\n::: {#782159d1 .cell execution_count=54}\n``` {.python .cell-code}\n# Fit the KMeans model to the data\nmodel.fit(X)\nmodel.cluster_centers_\n```\n\n::: {.cell-output .cell-output-display execution_count=1961}\n```\narray([[1.16666667, 1.46666667],\n       [7.33333333, 9.        ]])\n```\n:::\n:::\n\n\n## Interpreting $k$-means Results\n\n- After fitting, $k$-means provides cluster labels for each data point and the coordinates of the cluster centroids.\n- The labels indicate which cluster each data point belongs to.\n- The centroids represent the \"center\" of each cluster.\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {#23f289a9 .cell execution_count=55}\n``` {.python .cell-code}\nX[model.labels_ == 0]\n```\n\n::: {.cell-output .cell-output-display execution_count=1962}\n```\narray([[1. , 2. ],\n       [1.5, 1.8],\n       [1. , 0.6]])\n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#c8f6760b .cell execution_count=56}\n``` {.python .cell-code}\nX[model.labels_ == 1]\n```\n\n::: {.cell-output .cell-output-display execution_count=1963}\n```\narray([[ 5.,  8.],\n       [ 8.,  8.],\n       [ 9., 11.]])\n```\n:::\n:::\n\n\n:::\n\n::::\n\n## Plot it\n\n::: {#e2285489 .cell execution_count=57}\n``` {.python .cell-code}\nx, y = X.transpose()\nplt.scatter(x,y,c=model.labels_)\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-58-output-1.png){width=789 height=411}\n:::\n:::\n\n\n## Choosing $k$\n\n- Determining the optimal `k` is a common challenge in $k$-means.\n- The choice of `k` often depends on domain knowledge and the goal of the clustering.\n- We \"cheat\" on the digits set - there are 10 digits (exact)\n\n# Exercise\n\n## Cluster Digits\n\n- For the exercise we will cluster the digits.\n- We will use Principle Component Analysis (PCA) to reduce from 64 to fewer dimensions.\n\n## Principal Component Analysis\n\n- **Dimensionality reduction** technique.\n- Transforms high-dimensional data into fewer, uncorrelated **principal components**.\n- Components capture maximum data variance.\n\n::: {#b1540f91 .cell execution_count=58}\n``` {.python .cell-code}\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nX = np.random.rand(50, 5) # 50 samples, 5 features\nscaler = StandardScaler()\nscaled_X = scaler.fit_transform(X)\n```\n:::\n\n\n## PCA: Explained Variance\n\n- Each principal component captures a proportion of the total variance (**explained variance ratio**).\n- Helps decide how many components to keep.\n\n![](https://upload.wikimedia.org/wikipedia/commons/f/f5/GaussianScatterPCA.svg)\n\n## Code Sample\n\n::: {#65060385 .cell execution_count=59}\n``` {.python .cell-code}\npca = PCA(2)\nX_reduced = pca.fit_transform(scaled_X)\nX[:5], X_reduced[5]\n```\n\n::: {.cell-output .cell-output-display execution_count=1966}\n```\n(array([[0.38472853, 0.18100893, 0.68631295, 0.34187999, 0.12097866],\n        [0.56794642, 0.68288459, 0.24670022, 0.09408701, 0.09278339],\n        [0.02315102, 0.7190892 , 0.13918952, 0.85747553, 0.86630376],\n        [0.84121106, 0.49579156, 0.67995649, 0.78917103, 0.29252704],\n        [0.41194437, 0.30207129, 0.35975138, 0.8663255 , 0.15705037]]),\n array([-1.20963037,  0.45937525]))\n```\n:::\n:::\n\n\n## Benefits of PCA\n\n- **Simplifies data** and reduces storage.\n- Can **reduce noise**.\n- Useful for **visualization**.\n- **Important**: Data scaling is crucial.\n  \t- `StandardScaler().fit_transform()`\n\n## Exercise\n\n- Use PCA and $k$-means on the digit data.\n  \t- You may need to try different PCA numbers.\n- Look at a 2+ examples in 2+ clusters.\n- Plot the classification.\n  \t- I'll use PCA with 2 dimensions for `x` and `y`\n\t- Two plots, colored for actual and predicted.\n\n## Solution\n\n- $k$-means\n\n::: {#bc23cad5 .cell execution_count=60}\n``` {.python .cell-code code-fold=\"true\"}\nscaled = StandardScaler().fit_transform(data)\nreduced = PCA(10).fit_transform(scaled)\nmodel = KMeans(10)\n_ = model.fit(reduced)\n```\n:::\n\n\n## Looker\n\n- I wrote a function to look at things.\n\n::: {#351ea26b .cell execution_count=61}\n``` {.python .cell-code code-fold=\"true\"}\ndef looker(cluster, index):\n\tplt.imshow(data[model.labels_ == cluster][index].reshape(8,8), cmap='Greys')\n\tplt.axis('off')\n\tplt.show()\n```\n:::\n\n\n## Cluster 0\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {#63961df2 .cell execution_count=62}\n``` {.python .cell-code}\nlooker(0,0)\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-63-output-1.png){width=389 height=389}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#59582cd1 .cell execution_count=63}\n``` {.python .cell-code}\nlooker(0,1)\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-64-output-1.png){width=389 height=389}\n:::\n:::\n\n\n:::\n\n::::\n\n## Cluster 1\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {#9d3992e2 .cell execution_count=64}\n``` {.python .cell-code}\nlooker(1,0)\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-65-output-1.png){width=389 height=389}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#ed1dcd01 .cell execution_count=65}\n``` {.python .cell-code}\nlooker(1,1)\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-66-output-1.png){width=389 height=389}\n:::\n:::\n\n\n:::\n\n::::\n\n## Plot\n\n\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {#33e725b2 .cell execution_count=66}\n``` {.python .cell-code code-fold=\"true\"}\nreduced = PCA(2).fit_transform(scaled)\nx, y = reduced.transpose()\nplt.scatter(x,y,c=digits[\"target\"])\nplt.axis('off') # They are not relative to anything \"real\"\n_ = plt.title(\"Actual\")\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-67-output-1.png){width=763 height=409}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#bf45a4ec .cell execution_count=67}\n``` {.python .cell-code code-fold=\"true\"}\nreduced = PCA(2).fit_transform(scaled)\nx, y = reduced.transpose()\nplt.scatter(x,y,c=model.labels_)\nplt.axis('off') # They are not relative to anything \"real\"\n_ = plt.title(\"Predicted\")\n```\n\n::: {.cell-output .cell-output-display}\n![](09_sklearn_files/figure-revealjs/cell-68-output-1.png){width=763 height=409}\n:::\n:::\n\n\n:::\n\n::::\n\n",
    "supporting": [
      "09_sklearn_files\\figure-revealjs"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}