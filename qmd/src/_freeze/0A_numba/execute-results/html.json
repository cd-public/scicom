{
  "hash": "66e1721aa8f89c00b4008158bb470263",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Numba \n---\n\n\n\n\n\n\n# What is Numba?\n\n- `Numba` addresses a long-standing problem in scientific computing.\n  \t- Writing code in Python, instead of C or Fortran, is fast.\n\t- Running code in Python, instead of C or Fortran, is slow.\n\n## C/Fortran\n\t  \n- C and Fortran have been swimming around the periphery for some time.\n  \t- E.g. NumPy is written in C, uses C numbers.\n\t- E.g. SymPy can print C/Fortran code for expressions.\n- C is a general purpose language and the highest performance language in existence.\n- Fortran, for \"formula transcription\", is the foremost numerical computing platform (for performance).\n\n## Scripting\n\n- Python is a *scripting* language.\n  \t- Write code in `.py` file or within `python`\n\t- The `python` program \"runs\" the code\n\t- No program is created.\n\n## Vs. C/Fortran\n\n- C and Fortran are *compiled* languages.\n  \t- Write code.\n\t- Call a program, a **compiler**, on the code.\n\t- The compiler creates a **program**.\n\t- Run the program.\n\n## Numba\n\n- Numba is a compiler for Python.\n- More than that - a jit (just-in-time) compiler.\n- Numba looks and feels like Python, but under the hood is compiling Python code in fast, compiled languages.\n- It is a good halfway step to avoid having to learn C/Fortran.\n\n## In its own words:\n\n\n> [Numba is a compiler for Python array and numerical functions that gives you the power to speed up your applications with high performance functions written directly in Python.](https://numba.readthedocs.io/en/stable/user/overview.html)\n\n> [With a few simple annotations, array-oriented and math-heavy Python code can be just-in-time optimized to performance similar as C, C++ and Fortran, without having to switch languages or Python interpreters.](https://numba.readthedocs.io/en/stable/user/overview.html)\n\n## Why not Numba?\n\n- Just learn C or Fortran\n- Use Cython, an alternative Python compiler.\n- Use SymPy print-to-C/Fortran\n- Use GPU acceleration via PyTorch or Tensorflow for certain applications.\n\t- The Meta and Google GPU-accelerated frameworks, respectively.\n\t- `numba-cuda` (NVIDIA GPU Numba) exists, but I haven't seen it used much.\n\n\n# Install\n\n## Pip again!\n\n- Nothing special here.\n```{.bash code-line-numbers=\"false\"}\npython3 -m pip install numba\n```\n- Let's try it out.\n\n## Decorators\n\n- We need to introduce something called a *decorator*\n- It's a little note before a function definition that starts with `@`\n  \t- This means we'll mostly write functions to use Numba.\n- We'll do an example.\n\n## Import\n\n- Numba is essential a NumPy optimizer, so we'll include both.\n\n::: {#8e326615 .cell execution_count=2}\n``` {.python .cell-code}\nfrom numba import jit\nimport numpy as np\n```\n:::\n\n\n## Test it\n\n- `@jit` is the much-ballyhoo'ed *decorator*.\n\n::: {#716a2183 .cell execution_count=3}\n``` {.python .cell-code}\nx = np.arange(100).reshape(10, 10)\n\n@jit\ndef go_fast(a): # Function is compiled to machine code when called the first time\n    trace = 0.0\n    for i in range(a.shape[0]):   # Numba likes loops\n        trace += np.tanh(a[i, i]) # Numba likes NumPy functions\n    return a + trace              # Numba likes NumPy broadcasting\n\n_ = go_fast(x)\n```\n:::\n\n\n## Aside: **pandas**\n\n- Numba does *not* accelerate **pandas**\n- It is the \"numerical\" not \"data\" compiler.\n- Don't do this:\n\n::: {#bc7d3896 .cell execution_count=4}\n``` {.python .cell-code}\nimport pandas as pd\n\nx = {'a': [1, 2, 3], 'b': [20, 30, 40]}\n\n@jit(forceobj=True, looplift=True) # Need to use object mode, try and compile loops!\ndef use_pandas(a): # Function will not benefit from Numba jit\n    df = pd.DataFrame.from_dict(a) # Numba doesn't know about pd.DataFrame\n    df += 1                        # Numba doesn't understand what this is\n    return df.cov()                # or this!\n\n_ = use_pandas(x)\n```\n:::\n\n\n## Modes\n\n- Numba basically has two modes\n  \t- `object mode`: Slow Python mode, works for **pandas**\n\t- `nonpython`: Fast compiled mode, works for NumPy\n- I wouldn't bother with Numba unless you can use `nonpython`\n  \t- Basically Numba doesn't do anything.\n\n# Timing\n\n## time\n\n- It is hard to motivate Numba without seeing how fast it is.\n- We will introduce `time`\n\n::: {#c19faec3 .cell execution_count=5}\n``` {.python .cell-code}\nimport time\n\ntime.time()\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\n1749072691.494536\n```\n:::\n:::\n\n\n## perf_counter()\n\n- `time` supports `time.perf_counter()`\n\n> Return the value (in fractional seconds) of a performance counter, i.e. a clock with the highest available resolution to measure a short duration.\n\n- Let's try it out.\n\n## NumPy\n\n- I have have claimed NumPy vector operations are faster than base Python.\n- Let's test it.\n\n::: {#e247b0a9 .cell execution_count=6}\n``` {.python .cell-code}\npy_lst = list(range(1000000))\nnp_arr =  np.arange(1000000)\n\nlen(py_lst), len(np_arr)\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```\n(1000000, 1000000)\n```\n:::\n:::\n\n\n## Polynomial\n\n- We will write a simple polynomial.\n\n> [The Legendre polynomials were first introduced in 1782 by Adrien-Marie Legendre[5] as the coefficients in the expansion of the Newtonian potential...](https://en.wikipedia.org/wiki/Legendre_polynomials)\n\n> [...served as the fundamental gravitational potential in Newton's law of universal gravitation.](https://en.wikipedia.org/wiki/Newtonian_potential)\n\n## $P_{10}(x)$\n\n- We take $P_{10}(x)$, the 10th Legendre polynomial.\n\n$$\n\\tfrac{146189x^{10}-109395x^8+90090x^6-30030x^4+3465x^2-63}{256}\n$$\n\n- This uses only NumPy vectorizable operations:\n\n::: {#7c02c3ac .cell execution_count=7}\n``` {.python .cell-code}\ndef p_ten(x):\n\treturn (46189*x**10-109395*x**8+90090*x**6-30030*x**4+3456*x*2-63)//256\n\np_ten(np.arange(5))\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```\narray([       -1,        14,     96060,   8097412, 162596541])\n```\n:::\n:::\n\n\n## Timing\n\n- It is a straightforward matter to time Python vs NumPy\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {#ba482a21 .cell execution_count=8}\n``` {.python .cell-code}\nt = time.perf_counter()\n[p_ten(i) for i in py_lst] # Pythonic vector\npy_t = time.perf_counter() - t\n```\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#1b55b442 .cell execution_count=9}\n``` {.python .cell-code}\nt = time.perf_counter()\np_ten(np_arr) # NumPy vectorization\nnp_t = time.perf_counter() - t\n```\n:::\n\n\n:::\n\n::::\n\n- Compare the times - NumPy 24x faster.\n\n::: {#4452be43 .cell execution_count=10}\n``` {.python .cell-code}\npy_t, np_t, py_t/np_t, np_t/py_t\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```\n(1.053028100170195,\n 0.04169120010919869,\n 25.257802543752067,\n 0.0395917260920771)\n```\n:::\n:::\n\n\n# Compilation\n\n## Compiling\n\n- To compile a Numba function, we have to run at least once.\n- We will:\n  \t- Write a function.\n\t- Time it with NumPy\n\t- Add Numba decorators\n\t- Run once\n\t- Time it with Numba\n- Helpfully, we timed `p_ten()` with NumPy\n\n\n## Numba time.\n\n- Declare with `@jit`\n\n::: {#347549b9 .cell execution_count=11}\n``` {.python .cell-code}\n@jit\ndef p_ten_nb(x):\n\treturn (46189*x**10-109395*x**8+90090*x**6-30030*x**4+3456*x*2-63)//256\n```\n:::\n\n\n- Compile by running once...\n\n::: {#794cad10 .cell execution_count=12}\n``` {.python .cell-code}\n_ = p_ten_nb(np_arr)\n```\n:::\n\n\n- Time on the same array\n\n::: {#7e1b9d1b .cell execution_count=13}\n``` {.python .cell-code}\nt = time.perf_counter()\np_ten_nb(np_arr) # NumPy vectorization\nnb_t = time.perf_counter() - t\nnb_t\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```\n0.0041732999961823225\n```\n:::\n:::\n\n\n## Maybe 10x?\n\n- At first, not great!\n- Let's optimize.\n\n::: {#7aa8e9cb .cell execution_count=14}\n``` {.python .cell-code}\nnb_t, np_t, nb_t/np_t, np_t/nb_t\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```\n(0.0041732999961823225,\n 0.04169120010919869,\n 0.10010026061258744,\n 9.9899839808634)\n```\n:::\n:::\n\n\n## Using `jit`\n\n> [Numba provides several utilities for code generation, but its central feature is the numba.jit() decorator. Using this decorator, you can mark a function for optimization by Numbaâ€™s JIT compiler. Various invocation modes trigger differing compilation options and behaviours.](https://numba.pydata.org/numba-doc/dev/user/jit.html)\n\n## Parallel\n\n- Declare\n\n::: {#7b800c53 .cell execution_count=15}\n``` {.python .cell-code}\n@jit(nopython=True, parallel=True)\ndef p_ten_par(x):\n\treturn (46189*x**10-109395*x**8+90090*x**6-30030*x**4+3456*x*2-63)//256\n\n_ = p_ten_par(np_arr)  \n```\n:::\n\n\n- Time\n\n::: {#a9082afc .cell execution_count=16}\n``` {.python .cell-code}\nt = time.perf_counter()\np_ten_par(np_arr) # NumPy vectorization\npt_t = time.perf_counter() - t\npt_t\n```\n\n::: {.cell-output .cell-output-display execution_count=45}\n```\n0.0019292000215500593\n```\n:::\n:::\n\n\n## For me\n\n- My device is about twice as fast when parallelized.\n- I suspect much faster if I wasn't developing these slides while running servers, etc. in the background.\n\n::: {#adac459a .cell execution_count=17}\n``` {.python .cell-code}\n# pt = parallel=true time\npt_t, nb_t, pt_t/nb_t, nb_t/pt_t\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```\n(0.0019292000215500593,\n 0.0041732999961823225,\n 0.4622720684625752,\n 2.1632282550096544)\n```\n:::\n:::\n\n\n## Or...\n\n- Or maybe I just need more numbers.\n\n::: {#e015740a .cell execution_count=18}\n``` {.python .cell-code}\nnp_arr = np.arange(100000000, dtype=np.int64) # 100 mil\n```\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {#50619761 .cell execution_count=19}\n``` {.python .cell-code}\n@jit(nopython=True, parallel=False)\ndef p_ten(x):\n\treturn (46189*x**10-109395*x**8+90090*x**6-30030*x**4+3456*x*2-63)//256\n\np_ten(np_arr) # Compile\nt = time.perf_counter()\np_ten(np_arr)\npf = time.perf_counter() - t\npf\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```\n0.37826739996671677\n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#441f2a42 .cell execution_count=20}\n``` {.python .cell-code}\n@jit(nopython=True, parallel=True)\ndef p_ten(x):\n\treturn (46189*x**10-109395*x**8+90090*x**6-30030*x**4+3456*x*2-63)//256\n\np_ten(np_arr) # Compile\nt = time.perf_counter()\np_ten(np_arr)\npt = time.perf_counter() - t\npt\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```\n0.15015660016797483\n```\n:::\n:::\n\n\n:::\n\n::::\n\n## GIL\n\n- Python has a \"Global Interpreter Lock\" to ensure consistency of array operations.\n- All our array operations are independent, so we don't have to worry about any of that, I think.\n- We use `nogil`\n\n## nogil=True\n\n::: {#6f7c87dc .cell execution_count=21}\n``` {.python .cell-code}\n@jit(nopython=True, nogil=True, parallel=True)\ndef p_ten(x):\n\treturn (46189*x**10-109395*x**8+90090*x**6-30030*x**4+3456*x*2-63)//256\n\np_ten(np_arr) # Compile\nt = time.perf_counter()\np_ten(np_arr)\nng = time.perf_counter() - t\nng, pt # no gil, parallel true\n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```\n(0.14797269995324314, 0.15015660016797483)\n```\n:::\n:::\n\n\n- Doesn't do much here.\n\n## Signatures\n\n- Numba probably infers this, but it also benefits from knowing what kind of integer we are working with.\n- These are like the NumPy types.\n- Probably the biggest value... \n\n::: {#c90ec1c3 .cell execution_count=22}\n``` {.python .cell-code}\nbiggest = p_ten(max(np_arr))\nbiggest, np.iinfo(np.int32), np.iinfo(np.int64)\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```\n(22357606058205098,\n iinfo(min=-2147483648, max=2147483647, dtype=int32),\n iinfo(min=-9223372036854775808, max=9223372036854775807, dtype=int64))\n```\n:::\n:::\n\n\n- Fits in `np.int64`\n\n## cfunc\n\n- If we know the type of the values, we can use `cfunc` instead of `jit`\n- Compiles to C, may be faster!\n- Signatures are `out(in)`, so `/` is `float(int, int)`\n\n::: {#b45e5131 .cell execution_count=23}\n``` {.python .cell-code}\nx = 5\ny = 2\nz = x / y\ntype(z), type(x), type(y)\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```\n(float, int, int)\n```\n:::\n:::\n\n\n## Run it\n\n::: {#2682d529 .cell execution_count=24}\n``` {.python .cell-code}\nfrom numba import cfunc, int64\n\n@cfunc(int64(int64))\ndef p_ten(x):\n\treturn (46189*x**10-109395*x**8+90090*x**6-30030*x**4+3456*x*2-63)//256\n\np_ten(np_arr) # Compile\nt = time.perf_counter()\np_ten(np_arr)\ntime.perf_counter() - t\n```\n\n::: {.cell-output .cell-output-display execution_count=53}\n```\n4.166833899915218\n```\n:::\n:::\n\n\n- Meh. Works better with formulas than polynomials (exponentials and the like).\n\n## Aside: Intel\n\n- I tried a few Intel packages Numba recommended.\n- I got no noticeable changes from either, but mention them.\n\n## Intel SVML\n\n- These slides were compiled on an Intel device.\n- Numba recommends SVML for Intel devices.\n\n> Intel provides a short vector math library (SVML) that contains a large number of optimised transcendental functions available for use as compiler intrinsics\n\n```{.bash code-line-number=\"false\"}\npython3 -m pip install intel-cmplr-lib-rt\n```\n\n## Threading\n\n- For parallelism, Numba recommends `tbb` (Intel) or OpenMP (otherwise).\n- They are not available on all devices.\n- I could use `tbb`\n```{.bash code-line-number=\"false\"}\npython3 -m pip install tbb\n```\n\n\n## Floats\n\n- Numba works just fine with floats!\n\n::: {#ecb08938 .cell execution_count=25}\n``` {.python .cell-code}\nfloat_arr = np_arr / 7\n# add fastmath to decorator, change // to /\n# `njit` means `jit(nopython=True`\nfrom numba import njit\n\n@njit(parallel=True)\ndef p_ten(x):\n\treturn (46189.*x**10.-109395.*x**8.+90090.*x**6.-30030.*x**4.+3456.*x*2.-63.)/256.\n\np_ten(np_arr) # Compile\nt = time.perf_counter()\np_ten(np_arr)\nfloat_t = time.perf_counter() - t\nfloat_t\n```\n\n::: {.cell-output .cell-output-display execution_count=54}\n```\n0.9491886999458075\n```\n:::\n:::\n\n\n## Floats\n\n- I used integers, but if we use floats we should use the `fastmath` option.\n- It allows greater inaccuracy (remember float rounding) in exchange for faster operations.\n\n::: {#0cefaa45 .cell execution_count=26}\n``` {.python .cell-code}\n@njit(fastmath=True, parallel=True)\ndef p_ten(x):\n\treturn (46189.*x**10.-109395.*x**8.+90090.*x**6.-30030.*x**4.+3456.*x*2.-63.)/256.\n\np_ten(np_arr) # Compile\nt = time.perf_counter()\np_ten(np_arr)\nfast_t = time.perf_counter() - t\nfast_t, float_t, fast_t/float_t, float_t/fast_t\n```\n\n::: {.cell-output .cell-output-display execution_count=55}\n```\n(0.13959049992263317,\n 0.9491886999458075,\n 0.14706296011594205,\n 6.799808729619044)\n```\n:::\n:::\n\n\n# \"I'm so Julia.\" - Charli XCX {background-image=\"https://upload.wikimedia.org/wikipedia/commons/9/90/Charli_XCX-4059_%28cropped%29.jpg\"}\n\n## Julia Sets\n\n- The Julia set is a topic in complex dynamics.\n\n> [Examples include the mathematical models that describe the swinging of a clock pendulum, the flow of water in a pipe, the random motion of particles in the air, and the number of fish each springtime in a lake.](https://en.wikipedia.org/wiki/Dynamical_system)\n\n## Complex Quadratic Polynomials\n\n- While not required, a common class of dynamics systems are complex-valued polynomial functions of the second degree, so we take, e.g.\n\n::: {#9c8b3fb1 .cell execution_count=27}\n``` {.python .cell-code}\ndef f(z):\n\treturn z**2 -.4 + .6j\n```\n:::\n\n\n## Complex values\n\n- In Python, complex values are denoted as multiples of `j` (`i` is too frequently use).\n\n::: {#78a779e3 .cell execution_count=28}\n``` {.python .cell-code}\nz = 0 + 1j\nz ** 2\n```\n\n::: {.cell-output .cell-output-display execution_count=57}\n```\n(-1+0j)\n```\n:::\n:::\n\n\n- NumPy, they have `dtype=np.complex128`\n\n::: {#7bb6839e .cell execution_count=29}\n``` {.python .cell-code}\narr = np.array([0 + 1j])\narr.dtype\n```\n\n::: {.cell-output .cell-output-display execution_count=58}\n```\ndtype('complex128')\n```\n:::\n:::\n\n\n## Common Form\n\n- Often we refer to the these polynomials as follows:\n\n$$\nf_c(z) = z^2 + c\n$$\n\n- We refer to the Julia set related to such a polynomial as:\n\n$$\nJ(f_c)\n$$\n\n## Sets and Functions\n\n- The Julia set is the elements on the complex plane for which some function converges under repeated iteration.\n- For $J(f_c)$ it is the elements:\n\n$$\nJ(f_c) \\{ z \\in \\mathbb{C} : \\forall n \\in \\mathbb{N} : |f_c^nN(z)| \\leq R\n$$\n\n## On $R$\n\n- We define $R$ as\n$$\nR > 0 \\land R^2 - R > |c|\n$$\n- It is simple to restrict $|c| < 2$ and use $R = 2$\n\n## Exercise\n\n- Set a maximum number of iterations, say 1000\n- Set a complex value $|c| < 2$\n- Create a 2D array of complex values ranging from -2 to 2 ($|a| < 2$)\n  \t- I used `reshape` and `linspace` together.\n- Iterate $f_c$ on each value until either:\n  \t- Maximum iterations are reached, or\n\t- The output exceeds $R = 2$ - look at `np.absolute()`\n\n## Result\n\n- Use Numba to achieve higher numbers of iterations (which create sharper images).\n- Use Matplotlib `imshow` to plot the result.\n  \t- Plot real component as `x`, imaginary as `y`, and iterations as color.\n- I recommend using $c = -0.4 + 0.6i$ which I think looks nice.\n\t- But you may choose your own $c$\n\n\n## $f_c^n(z)$\n\n- Apply `f_c`\n\t- Which, recall, is $z^2+c$\n- To `z`\n  \t- The elements of the array.\n- $n$ times\n\t- So $f_c^2(z) = f_c(f_c(z))$\n\n::: {#89bffba8 .cell execution_count=30}\n``` {.python .cell-code}\ndef f_c_n(z, c, n):\n\tfor i in range(n): # \"do thing n times\"\n\t\tz = z**2 + c\n\treturn z\n```\n:::\n\n\n## Solution\n\n::: {#5bedc453 .cell execution_count=31}\n``` {.python .cell-code code-fold=\"true\"}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom numba import njit\n\n@njit\ndef iterator(m, c, z):\n    for i in range(m):\n        z = z**2 + c\n        if (np.absolute(z) > 2):\n                return i\n    return i\n\n# m: max iterations, c: c\ndef j_f(m, c):\n    real = np.linspace(-2,2,1000)\n    imag = (0 + 1j) * real\n    comp = real.reshape(-1,1) + imag\n    f_vec = np.vectorize(iterator, excluded={0,1})\n    return f_vec(m, c, comp)\n\n# m: max iterations, c: c\ndef visualize(m, c):\n    arr = j_f(m,c)\n    plt.imshow(arr)\n    plt.axis('off')\n    plt.savefig(\"julia.png\", bbox_inches=\"tight\", pad_inches=0)\n\nvisualize(1000, -0.4 + 0.6j)\n```\n\n::: {.cell-output .cell-output-display}\n![](0A_numba_files/figure-revealjs/cell-31-output-1.png){width=389 height=389}\n:::\n:::\n\n\n",
    "supporting": [
      "0A_numba_files\\figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}